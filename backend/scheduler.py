# backend/scheduler.py
"""æµæ°´çº¿å®šæ—¶è°ƒåº¦å™¨"""
import threading
import time
from datetime import datetime
from typing import Optional
from croniter import croniter
from backend.pipeline_manager import PipelineManager
from backend.handlers import BuildManager


class PipelineScheduler:
    """æµæ°´çº¿å®šæ—¶è°ƒåº¦å™¨"""
    
    def __init__(self):
        self.running = False
        self.thread: Optional[threading.Thread] = None
        self.pipeline_manager = PipelineManager()
        self.build_manager = None  # å»¶è¿Ÿåˆå§‹åŒ–
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            print("âš ï¸ è°ƒåº¦å™¨å·²åœ¨è¿è¡Œ")
            return
        
        self.running = True
        self.thread = threading.Thread(target=self._run, daemon=True)
        self.thread.start()
        print("âœ… æµæ°´çº¿è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.running:
            return
        
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
        print("âœ… æµæ°´çº¿è°ƒåº¦å™¨å·²åœæ­¢")
    
    def _run(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯"""
        last_agent_check = 0
        agent_check_interval = 60  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡Agentä¸»æœº
        last_portainer_check = 0
        portainer_check_interval = 120  # æ¯120ç§’æ£€æŸ¥ä¸€æ¬¡Portainerä¸»æœºï¼ˆä½¿ç”¨è¾ƒé•¿çš„é—´éš”ï¼Œé¿å…é¢‘ç¹æ£€æµ‹ï¼‰
        last_docker_refresh = 0
        docker_refresh_interval = 1800  # æ¯30åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡Dockerä¿¡æ¯ç¼“å­˜
        
        while self.running:
            try:
                self._check_pipelines()
                
                current_time = time.time()
                
                # å®šæœŸæ£€æŸ¥Agentä¸»æœºç¦»çº¿çŠ¶æ€
                if current_time - last_agent_check >= agent_check_interval:
                    self._check_agent_hosts()
                    last_agent_check = current_time
                
                # å®šæœŸæ£€æŸ¥Portainerä¸»æœºçŠ¶æ€
                if current_time - last_portainer_check >= portainer_check_interval:
                    self._check_portainer_hosts()
                    last_portainer_check = current_time
                
                # å®šæœŸåˆ·æ–°Dockerä¿¡æ¯ç¼“å­˜
                if current_time - last_docker_refresh >= docker_refresh_interval:
                    self._refresh_docker_info()
                    last_docker_refresh = current_time
            except Exception as e:
                print(f"âŒ è°ƒåº¦å™¨æ‰§è¡Œå‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
            
            # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            time.sleep(60)
    
    def _check_pipelines(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œåˆ°æœŸçš„æµæ°´çº¿"""
        now = datetime.now()
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„æµæ°´çº¿
        pipelines = self.pipeline_manager.list_pipelines(enabled=True)
        
        for pipeline in pipelines:
            cron_expr = pipeline.get("cron_expression")
            if not cron_expr:
                continue
            
            pipeline_id = pipeline.get("pipeline_id")
            
            try:
                # éªŒè¯ cron è¡¨è¾¾å¼
                if not croniter.is_valid(cron_expr):
                    print(f"âš ï¸ æµæ°´çº¿ {pipeline_id} çš„ cron è¡¨è¾¾å¼æ— æ•ˆ: {cron_expr}")
                    continue
                
                # è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                next_run = pipeline.get("next_run_time")
                
                if next_run is None:
                    # é¦–æ¬¡è¿è¡Œï¼Œè®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                    cron = croniter(cron_expr, now)
                    next_run_time = cron.get_next(datetime)
                    self._update_next_run_time(pipeline_id, next_run_time)
                    print(f"ğŸ“… æµæ°´çº¿ {pipeline['name']} ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run_time}")
                    continue
                
                # è§£æä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                next_run_dt = datetime.fromisoformat(next_run)
                
                # æ£€æŸ¥æ˜¯å¦åˆ°æœŸ
                if now >= next_run_dt:
                    print(f"ğŸš€ è§¦å‘å®šæ—¶æµæ°´çº¿: {pipeline['name']}")
                    self._trigger_pipeline(pipeline)
                    
                    # è®¡ç®—æ–°çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                    cron = croniter(cron_expr, now)
                    next_run_time = cron.get_next(datetime)
                    self._update_next_run_time(pipeline_id, next_run_time)
                    print(f"ğŸ“… æµæ°´çº¿ {pipeline['name']} æ–°çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run_time}")
            
            except Exception as e:
                print(f"âŒ å¤„ç†æµæ°´çº¿ {pipeline_id} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
    
    def _update_next_run_time(self, pipeline_id: str, next_run_time: datetime):
        """æ›´æ–°æµæ°´çº¿çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´"""
        try:
            pipeline = self.pipeline_manager.get_pipeline(pipeline_id)
            if pipeline:
                pipeline["next_run_time"] = next_run_time.isoformat()
                # ç›´æ¥ä¿å­˜
                self.pipeline_manager._save_pipelines()
        except Exception as e:
            print(f"âŒ æ›´æ–°ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´å¤±è´¥: {e}")
    
    def _trigger_pipeline(self, pipeline: dict):
        """è§¦å‘æµæ°´çº¿æ„å»º"""
        try:
            pipeline_id = pipeline.get("pipeline_id")
            pipeline_name = pipeline.get("name", "unknown")
            
            # ä»æµæ°´çº¿é…ç½®ç”Ÿæˆä»»åŠ¡é…ç½®JSON
            from backend.handlers import pipeline_to_task_config
            task_config = pipeline_to_task_config(pipeline, trigger_source="cron")
            
            # æ£€æŸ¥é˜²æŠ–å’Œç›¸åŒä¿¡æ¯ï¼ˆ3ç§’å†…ç›¸åŒä¿¡æ¯è¦å±è”½ï¼‰
            is_same_trigger = self.pipeline_manager.check_same_trigger_info(
                pipeline_id, task_config, debounce_seconds=3
            )
            if is_same_trigger:
                # 3ç§’å†…ç›¸åŒä¿¡æ¯ï¼Œå±è”½
                print(
                    f"ğŸš« æµæ°´çº¿ {pipeline_name} è§¦å‘è¢«å±è”½ï¼ˆ3ç§’å†…ç›¸åŒä¿¡æ¯ï¼‰"
                )
                return
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            current_task_id = self.pipeline_manager.get_pipeline_running_task(pipeline_id)
            if current_task_id:
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦çœŸçš„åœ¨è¿è¡Œ
                if self.build_manager is None:
                    self.build_manager = BuildManager()
                
                task = self.build_manager.task_manager.get_task(current_task_id)
                if task and task.get("status") in ["pending", "running"]:
                    # æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œç«‹å³åˆ›å»ºæ–°ä»»åŠ¡ï¼ˆçŠ¶æ€ä¸º pendingï¼Œç­‰å¾…æ‰§è¡Œï¼‰
                    task_id = self.build_manager._trigger_task_from_config(task_config)
                    # æ›´æ–°æœ€åä¸€æ¬¡è§¦å‘çš„é…ç½®ä¿¡æ¯
                    self.pipeline_manager.update_last_trigger_config(pipeline_id, task_config)
                    queue_length = self.pipeline_manager.get_queue_length(pipeline_id)
                    print(f"âš ï¸ æµæ°´çº¿ {pipeline_name} å·²æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ {current_task_id[:8]}ï¼Œå·²åˆ›å»ºæ–°ä»»åŠ¡ï¼ˆpendingï¼‰ï¼Œé˜Ÿåˆ—é•¿åº¦: {queue_length}")
                    return
                else:
                    # ä»»åŠ¡å·²å®Œæˆæˆ–ä¸å­˜åœ¨ï¼Œè§£ç»‘
                    self.pipeline_manager.unbind_task(pipeline_id)
            
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            if self.build_manager is None:
                self.build_manager = BuildManager()
            
            # æ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ï¼Œç«‹å³å¯åŠ¨æ„å»ºä»»åŠ¡
            task_id = self.build_manager._trigger_task_from_config(task_config)
            # æ›´æ–°æœ€åä¸€æ¬¡è§¦å‘çš„é…ç½®ä¿¡æ¯
            self.pipeline_manager.update_last_trigger_config(pipeline_id, task_config)
            
            print(f"âœ… å®šæ—¶è§¦å‘æµæ°´çº¿: {pipeline_name}, ä»»åŠ¡ID: {task_id[:8]}")
            
            # è®°å½•è§¦å‘å¹¶ç»‘å®šä»»åŠ¡ï¼ˆå®šæ—¶è§¦å‘ï¼‰
            self.pipeline_manager.record_trigger(
                pipeline_id, 
                task_id,
                trigger_source="cron",
                trigger_info={
                    "cron_expression": pipeline.get("cron_expression"),
                    "branch": pipeline.get("branch"),
                }
            )
            
        except Exception as e:
            pipeline_name = pipeline.get("name", "unknown")
            print(f"âŒ è§¦å‘æµæ°´çº¿ {pipeline_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _check_agent_hosts(self):
        """æ£€æŸ¥å¹¶æ›´æ–°ç¦»çº¿Agentä¸»æœº"""
        try:
            from backend.agent_host_manager import AgentHostManager
            manager = AgentHostManager()
            manager.check_offline_hosts(timeout_seconds=60)
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥Agentä¸»æœºçŠ¶æ€å¤±è´¥: {e}")
    
    def _check_portainer_hosts(self):
        """æ£€æŸ¥Portainerä¸»æœºçŠ¶æ€"""
        try:
            from backend.agent_host_manager import AgentHostManager
            manager = AgentHostManager()
            manager.check_portainer_hosts_status()
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥Portainerä¸»æœºå¤±è´¥: {e}")
    
    def _refresh_docker_info(self):
        """åˆ·æ–°Dockerä¿¡æ¯ç¼“å­˜"""
        try:
            from backend.docker_info_cache import docker_info_cache
            docker_info_cache.refresh_cache()
            print("âœ… Dockerä¿¡æ¯ç¼“å­˜å·²åˆ·æ–°ï¼ˆåå°ä»»åŠ¡ï¼‰")
        except Exception as e:
            print(f"âš ï¸ åˆ·æ–°Dockerä¿¡æ¯ç¼“å­˜å¤±è´¥: {e}")


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_scheduler: Optional[PipelineScheduler] = None


def get_scheduler() -> PipelineScheduler:
    """è·å–è°ƒåº¦å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _scheduler
    if _scheduler is None:
        _scheduler = PipelineScheduler()
    return _scheduler


def start_scheduler():
    """å¯åŠ¨è°ƒåº¦å™¨"""
    scheduler = get_scheduler()
    scheduler.start()


def stop_scheduler():
    """åœæ­¢è°ƒåº¦å™¨"""
    scheduler = get_scheduler()
    scheduler.stop()
