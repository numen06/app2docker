# handlers.py
import json
import os
import re
import shutil
import subprocess
import threading
import urllib
import uuid
import gzip
import zipfile
import tarfile
from datetime import datetime, timedelta
from collections import defaultdict, deque
from http.server import BaseHTTPRequestHandler
from urllib import parse
import yaml

from backend.config import (
    load_config,
    save_config,
    CONFIG_FILE,
    get_git_config,
    get_registry_by_name,
    get_active_registry,
    get_all_registries,
)
from backend.utils import generate_image_name, get_safe_filename
from backend.auth import authenticate, verify_token, require_auth

# ç›®å½•é…ç½®
UPLOAD_DIR = "data/uploads"
BUILD_DIR = "data/docker_build"
EXPORT_DIR = "data/exports"
LOGS_DIR = "data/logs"  # æ“ä½œæ—¥å¿—ç›®å½•
# æ¨¡æ¿ç›®å½•ï¼šå†…ç½®æ¨¡æ¿ï¼ˆåªè¯»ï¼‰+ ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿ï¼ˆå¯è¯»å†™ï¼‰
BUILTIN_TEMPLATES_DIR = "templates"  # å†…ç½®æ¨¡æ¿ï¼Œæ‰“åŒ…åˆ°Dockeré•œåƒä¸­
USER_TEMPLATES_DIR = "data/templates"  # ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿ï¼Œé€šè¿‡Dockeræ˜ å°„æŒä¹…åŒ–
# å‰ç«¯æ–‡ä»¶
DIST_DIR = "dist"  # å‰ç«¯æ„å»ºäº§ç‰©
INDEX_FILE = "dist/index.html"  # å‰ç«¯å…¥å£æ–‡ä»¶

# å¯¼å…¥ Docker æ„å»ºå™¨
from backend.docker_builder import create_docker_builder

# å…¨å±€ Docker æ„å»ºå™¨ï¼ˆåœ¨é…ç½®æ›´æ–°æ—¶ä¼šé‡æ–°åˆ›å»ºï¼‰
docker_builder = None
DOCKER_AVAILABLE = False


def init_docker_builder():
    """åˆå§‹åŒ– Docker æ„å»ºå™¨"""
    global docker_builder, DOCKER_AVAILABLE
    config = load_config()
    docker_config = config.get("docker", {})
    docker_builder = create_docker_builder(docker_config)
    DOCKER_AVAILABLE = docker_builder.is_available()
    print(f"ğŸ³ Docker æ„å»ºå™¨å·²åˆå§‹åŒ–: {docker_builder.get_connection_info()}")
    return docker_builder


# åœ¨æ¨¡å—åŠ è½½æ—¶åˆå§‹åŒ–
try:
    init_docker_builder()
except Exception as e:
    print(f"âš ï¸ åˆå§‹åŒ– Docker æ„å»ºå™¨å¤±è´¥: {e}")


def natural_sort_key(s):
    return [
        int(text) if text.isdigit() else text.lower() for text in re.split(r"(\d+)", s)
    ]


# === æ¨¡æ¿ç›®å½•è¾…åŠ©å‡½æ•° ===
def get_all_templates():
    """è·å–æ‰€æœ‰æ¨¡æ¿åˆ—è¡¨ï¼ˆå†…ç½® + ç”¨æˆ·è‡ªå®šä¹‰ï¼‰ï¼Œæ”¯æŒå­ç›®å½•åˆ†ç±»ï¼Œç”¨æˆ·æ¨¡æ¿ä¼˜å…ˆ"""
    templates = {}

    def scan_templates(base_dir, template_type):
        """æ‰«ææ¨¡æ¿ç›®å½•ï¼Œæ”¯æŒå­ç›®å½•ï¼ˆé¡¹ç›®ç±»å‹ï¼‰"""
        if not os.path.exists(base_dir):
            return

        # æ‰«ææ ¹ç›®å½•çš„æ¨¡æ¿ï¼ˆå‘åå…¼å®¹ï¼‰
        for f in os.listdir(base_dir):
            if f.endswith(".Dockerfile"):
                name = f.replace(".Dockerfile", "")
                # ä»æ–‡ä»¶åæ¨æ–­é¡¹ç›®ç±»å‹ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
                project_type = "nodejs" if "node" in name.lower() else "jar"
                templates[name] = {
                    "name": name,
                    "path": os.path.join(base_dir, f),
                    "type": template_type,
                    "project_type": project_type,
                }

        # æ‰«æå­ç›®å½•ï¼ˆé¡¹ç›®ç±»å‹ç›®å½•ï¼‰
        for project_type in os.listdir(base_dir):
            type_dir = os.path.join(base_dir, project_type)
            if not os.path.isdir(type_dir):
                continue

            # è·³è¿‡éšè—ç›®å½•å’Œç‰¹æ®Šç›®å½•
            if project_type.startswith(".") or project_type.startswith("_"):
                continue

            for f in os.listdir(type_dir):
                if f.endswith(".Dockerfile"):
                    name = f.replace(".Dockerfile", "")
                    templates[name] = {
                        "name": name,
                        "path": os.path.join(type_dir, f),
                        "type": template_type,
                        "project_type": project_type,
                    }

    # 1. å…ˆåŠ è½½å†…ç½®æ¨¡æ¿
    scan_templates(BUILTIN_TEMPLATES_DIR, "builtin")

    # 2. å†åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿ï¼ˆä¼šè¦†ç›–åŒåå†…ç½®æ¨¡æ¿ï¼‰
    scan_templates(USER_TEMPLATES_DIR, "user")

    return templates


def get_template_path(template_name, project_type=None):
    """è·å–æŒ‡å®šæ¨¡æ¿çš„æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒå­ç›®å½•ï¼Œä¼˜å…ˆè¿”å›ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿"""
    filename = f"{template_name}.Dockerfile"

    # å¦‚æœæŒ‡å®šäº†é¡¹ç›®ç±»å‹ï¼Œä¼˜å…ˆåœ¨å¯¹åº”å­ç›®å½•ä¸­æŸ¥æ‰¾
    if project_type:
        # ä¼˜å…ˆæŸ¥æ‰¾ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿ï¼ˆå­ç›®å½•ï¼‰
        user_type_path = os.path.join(USER_TEMPLATES_DIR, project_type, filename)
        if os.path.exists(user_type_path):
            return user_type_path

        # æŸ¥æ‰¾å†…ç½®æ¨¡æ¿ï¼ˆå­ç›®å½•ï¼‰
        builtin_type_path = os.path.join(BUILTIN_TEMPLATES_DIR, project_type, filename)
        if os.path.exists(builtin_type_path):
            return builtin_type_path

    # å¦‚æœæ²¡æœ‰æŒ‡å®šé¡¹ç›®ç±»å‹ï¼Œéå†æ‰€æœ‰å­ç›®å½•æŸ¥æ‰¾
    if not project_type:
        for ptype in ["jar", "nodejs", "python", "go", "rust", "web"]:
            # ç”¨æˆ·æ¨¡æ¿ç›®å½•
            user_type_path = os.path.join(USER_TEMPLATES_DIR, ptype, filename)
            if os.path.exists(user_type_path):
                return user_type_path

            # å†…ç½®æ¨¡æ¿ç›®å½•
            builtin_type_path = os.path.join(BUILTIN_TEMPLATES_DIR, ptype, filename)
            if os.path.exists(builtin_type_path):
                return builtin_type_path

    # åœ¨æ ¹ç›®å½•æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
    user_path = os.path.join(USER_TEMPLATES_DIR, filename)
    if os.path.exists(user_path):
        return user_path

    builtin_path = os.path.join(BUILTIN_TEMPLATES_DIR, filename)
    if os.path.exists(builtin_path):
        return builtin_path

    return None


def get_user_template_path(template_name, project_type="jar"):
    """è·å–ç”¨æˆ·æ¨¡æ¿çš„ä¿å­˜è·¯å¾„ï¼ˆç”¨äºæ–°å»º/ç¼–è¾‘ï¼‰ï¼Œä¿å­˜åˆ°å¯¹åº”çš„é¡¹ç›®ç±»å‹å­ç›®å½•"""
    type_dir = os.path.join(USER_TEMPLATES_DIR, project_type)
    os.makedirs(type_dir, exist_ok=True)
    return os.path.join(type_dir, f"{template_name}.Dockerfile")


class Jar2DockerHandler(BaseHTTPRequestHandler):
    server_version = "Jar2Docker/1.0"

    def _send_json(self, code, data):
        try:
            self.send_response(code)
            self.send_header("Content-Type", "application/json; charset=utf-8")
            self.end_headers()
            self.wfile.write(
                json.dumps(data, ensure_ascii=False, indent=2).encode("utf-8")
            )
        except Exception as e:
            print(f"âŒ å‘é€ JSON å“åº”å¤±è´¥: {e}")

    def _send_html(self, content):
        try:
            self.send_response(200)
            self.send_header("Content-Type", "text/html; charset=utf-8")
            self.end_headers()
            if isinstance(content, str):
                content = content.encode("utf-8")
            self.wfile.write(content)
        except Exception as e:
            print(f"âŒ å‘é€ HTML å“åº”å¤±è´¥: {e}")

    def _get_content_type(self, filepath):
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å› MIME ç±»å‹"""
        ext = os.path.splitext(filepath)[1].lower()
        mime_types = {
            ".css": "text/css",
            ".js": "application/javascript",
            ".json": "application/json",
            ".png": "image/png",
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".gif": "image/gif",
            ".svg": "image/svg+xml",
            ".ico": "image/x-icon",
            ".woff": "application/font-woff",
            ".woff2": "font/woff2",
            ".ttf": "application/font-sfnt",
            ".otf": "application/font-sfnt",
            ".eot": "application/vnd.ms-fontobject",
            ".html": "text/html",
            ".htm": "text/html",
            ".xml": "text/xml",
            ".txt": "text/plain",
        }
        return mime_types.get(ext, "application/octet-stream")

    def _send_file(
        self, filepath, content_type="application/octet-stream", download_name=None
    ):
        try:
            if not os.path.exists(filepath):
                self.send_error(404, "File not found")
                return False

            self.send_response(200)
            self.send_header("Content-Type", content_type)
            if download_name:
                self.send_header(
                    "Content-Disposition", f'attachment; filename="{download_name}"'
                )
            self.send_header("Content-Length", str(os.path.getsize(filepath)))
            self.end_headers()

            with open(filepath, "rb") as f:
                shutil.copyfileobj(f, self.wfile)
            return True
        except Exception as e:
            print(f"âŒ å‘é€æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
            return False

    def do_GET(self):
        path = self.path.split("?")[0]

        if path == "/get-config":
            self.handle_get_config()
        elif path == "/get-logs":
            # åœ¨ do_GET ä¸­ï¼š
            parsed_url = parse.urlparse(self.path)
            query_params = parse.parse_qs(parsed_url.query)  # è¿”å› dictï¼Œå€¼æ˜¯ list
            build_id = query_params.get("build_id", [None])[0]
            if build_id:
                self.handle_get_logs(build_id)
            else:
                self.send_error(400, "ç¼ºå°‘ build_id å‚æ•°")
        elif path == "/list-templates":
            self.handle_list_templates()
        elif path == "/templates":
            parsed_url = parse.urlparse(self.path)
            query_params = parse.parse_qs(parsed_url.query)
            template_name = (query_params.get("name", [None])[0] or "").strip()
            if template_name:
                self.handle_get_template(template_name)
            else:
                self.handle_templates_summary()
        elif path.startswith("/templates/"):
            rel_path = path[len("/templates/") :].lstrip("/")
            if ".." in rel_path or rel_path.startswith("/"):
                self.send_error(400, "éæ³•æ¨¡æ¿è·¯å¾„")
                return
            filepath = os.path.join(TEMPLATES_DIR, rel_path)
            abs_templates = os.path.abspath(TEMPLATES_DIR)
            abs_target = os.path.abspath(filepath)
            try:
                if os.path.commonpath([abs_templates, abs_target]) != abs_templates:
                    self.send_error(400, "éæ³•æ¨¡æ¿è·¯å¾„")
                    return
            except ValueError:
                self.send_error(400, "éæ³•æ¨¡æ¿è·¯å¾„")
                return
            if os.path.exists(filepath):
                self._send_file(filepath, "text/plain; charset=utf-8")
            else:
                self.send_error(404, "æ¨¡æ¿ä¸å­˜åœ¨")
        elif path == "/export-image":
            parsed_url = parse.urlparse(self.path)
            query_params = parse.parse_qs(parsed_url.query)
            self.handle_export_image(query_params)
        elif path == "/" or path == "/index.html":
            self.serve_index()
        elif path.startswith("/static/"):
            filepath = path.lstrip("/")
            if os.path.exists(filepath):
                # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®š MIME ç±»å‹
                content_type = self._get_content_type(filepath)
                self._send_file(filepath, content_type)
            else:
                self.send_error(404)
        elif path.startswith("/favicon"):
            # å¤„ç† favicon è¯·æ±‚
            filepath = path.lstrip("/")
            if os.path.exists(filepath):
                content_type = self._get_content_type(filepath)
                self._send_file(filepath, content_type)
            else:
                self.send_error(404)
        elif path == "/generate_favicon.html":
            # Favicon ç”Ÿæˆå·¥å…·é¡µé¢
            if os.path.exists("generate_favicon.html"):
                self._send_file("generate_favicon.html", "text/html")
            else:
                self.send_error(404)
        else:
            self.send_error(404)

    def do_PUT(self):
        path = self.path.split("?")[0]
        if path == "/templates":
            self.handle_update_template()
        else:
            self.send_error(404)

    def do_DELETE(self):
        path = self.path.split("?")[0]
        if path == "/templates":
            self.handle_delete_template()
        else:
            self.send_error(404)

    # === æ–°å¢ï¼šè·å–æ—¥å¿— ===
    def handle_get_logs(self, build_id):
        try:
            manager = BuildManager()
            logs = manager.get_logs(build_id)  # å‡è®¾è¿”å› list[str] æˆ– str
            log_text = "".join(logs) if isinstance(logs, list) else str(logs)

            self.send_response(200)
            self.send_header("Content-Type", "text/plain; charset=utf-8")
            self.end_headers()
            self.wfile.write(log_text.encode("utf-8"))
        except Exception as e:
            self.send_error(500, f"è·å–æ—¥å¿—å¤±è´¥: {e}")

    def serve_index(self):
        if os.path.exists(INDEX_FILE):
            with open(INDEX_FILE, "r", encoding="utf-8") as f:
                content = f.read()
            self._send_html(content)
        else:
            self.send_error(404, "index.html not found")

    def handle_login(self):
        """å¤„ç†ç™»å½•è¯·æ±‚"""
        try:
            data = self._read_json_body()
            username = data.get("username", "").strip()
            password = data.get("password", "").strip()

            if not username or not password:
                self._send_json(400, {"error": "ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º"})
                return

            result = authenticate(username, password)

            if result["success"]:
                self._send_json(
                    200,
                    {
                        "success": True,
                        "token": result["token"],
                        "username": result["username"],
                        "expires_in": result["expires_in"],
                    },
                )
            else:
                self._send_json(401, {"error": result["error"]})
        except Exception as e:
            self._send_json(500, {"error": f"ç™»å½•å¤±è´¥: {str(e)}"})

    def handle_logout(self):
        """å¤„ç†ç™»å‡ºè¯·æ±‚"""
        # JWT æ˜¯æ— çŠ¶æ€çš„ï¼Œç™»å‡ºä¸»è¦åœ¨å®¢æˆ·ç«¯åˆ é™¤ token
        self._send_json(200, {"success": True, "message": "ç™»å‡ºæˆåŠŸ"})

    def handle_get_config(self):
        try:
            config = load_config()
            docker_config = config.get("docker", {})
            self._send_json(200, {"docker": docker_config})
        except Exception as e:
            import traceback

            traceback.print_exc()
            self._send_json(500, {"error": f"è·å–é…ç½®å¤±è´¥: {str(e)}"})

    def handle_list_templates(self):
        try:
            details = self._collect_template_details()
            templates = [item["name"] for item in details]
            self._send_json(200, {"templates": templates, "template_details": details})
        except Exception as e:
            import traceback

            traceback.print_exc()
            self._send_json(500, {"error": "è·å–æ¨¡æ¿åˆ—è¡¨å¤±è´¥"})

    def handle_templates_summary(self):
        try:
            details = self._collect_template_details()
            self._send_json(
                200, {"templates": [item["name"] for item in details], "items": details}
            )
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(
                500, {"error": f"è·å–æ¨¡æ¿ä¿¡æ¯å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"}
            )

    def handle_get_template(self, template_name):
        try:
            template_path, clean_name, filename = self._resolve_template_path(
                template_name
            )
            if not os.path.exists(template_path):
                self._send_json(404, {"error": "æ¨¡æ¿ä¸å­˜åœ¨"})
                return
            with open(template_path, "r", encoding="utf-8") as f:
                content = f.read()
            self._send_json(
                200, {"name": clean_name, "filename": filename, "content": content}
            )
        except ValueError as ve:
            self._send_json(400, {"error": str(ve)})
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(500, {"error": f"è·å–æ¨¡æ¿å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"})

    def handle_export_image(self, query_params):
        if not DOCKER_AVAILABLE:
            self._send_json(503, {"error": "Docker æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯¼å‡ºé•œåƒ"})
            return

        image_input = (query_params.get("image", [None])[0] or "").strip()
        tag_param = (query_params.get("tag", [""])[0] or "").strip()
        compress_param = (
            (query_params.get("compress", ["none"])[0] or "none").strip().lower()
        )

        if not image_input:
            self._send_json(400, {"error": "ç¼ºå°‘ image å‚æ•°"})
            return

        image_name = image_input
        tag = tag_param or "latest"

        if ":" in image_name and not tag_param:
            image_name, inferred_tag = image_name.rsplit(":", 1)
            if inferred_tag:
                tag = inferred_tag

        full_tag = f"{image_name}:{tag}"
        compress_enabled = compress_param in ("gzip", "gz", "tgz", "1", "true", "yes")
        config = load_config()
        docker_cfg = config.get("docker", {})
        username = docker_cfg.get("username")
        password = docker_cfg.get("password")
        auth_config = None
        if username and password:
            auth_config = {"username": username, "password": password}

        try:
            # ä½¿ç”¨ docker_builder
            pull_stream = docker_builder.pull_image(image_name, tag, auth_config)
            for chunk in pull_stream:
                if "error" in chunk:
                    raise RuntimeError(chunk["error"])

            docker_builder.get_image(full_tag)  # ç¡®è®¤é•œåƒå­˜åœ¨

            os.makedirs(EXPORT_DIR, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            safe_base = get_safe_filename(image_name.replace("/", "_") or "image")
            tar_filename = f"{safe_base}-{tag}-{timestamp}.tar"
            tar_path = os.path.join(EXPORT_DIR, tar_filename)

            image_stream = docker_builder.export_image(full_tag)
            with open(tar_path, "wb") as f:
                for chunk in image_stream:
                    f.write(chunk)

            final_path = tar_path
            download_name = tar_filename
            content_type = "application/x-tar"

            if compress_enabled:
                final_path = f"{tar_path}.gz"
                download_name = os.path.basename(final_path)
                content_type = "application/gzip"
                with open(tar_path, "rb") as src, gzip.open(final_path, "wb") as dst:
                    shutil.copyfileobj(src, dst)
                os.remove(tar_path)

            success = self._send_file(
                final_path, content_type, download_name=download_name
            )
            if success:
                try:
                    os.remove(final_path)
                except OSError:
                    pass
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip() or "æœªçŸ¥é”™è¯¯"
            self._send_json(500, {"error": f"å¯¼å‡ºé•œåƒå¤±è´¥: {clean_msg}"})

    def do_POST(self):
        path = self.path.split("?")[0]
        if path == "/login":
            self.handle_login()
        elif path == "/logout":
            self.handle_logout()
        elif path == "/upload":
            self.handle_upload()
        elif path == "/save-config":
            self.handle_save_config()
        elif path == "/suggest-image-name":
            self.handle_suggest_image_name()
        elif path == "/parse-compose":
            self.handle_parse_compose()
        elif path == "/templates":
            self.handle_create_template()
        else:
            self.send_error(404)

    def handle_suggest_image_name(self):
        try:
            content_length = int(self.headers["Content-Length"])
            body = self.rfile.read(content_length)

            boundary = self.headers["Content-Type"].split("boundary=")[1].encode()
            parts = body.split(b"--" + boundary)

            app_filename = None
            for part in parts[1:-1]:
                if (
                    b"\r\n\r\n" in part
                    and b'name="jar_file"' in part
                    and b'filename="' in part
                ):
                    headers = part[: part.find(b"\r\n\r\n")].decode(
                        "utf-8", errors="ignore"
                    )
                    match = re.search(r'filename="(.+?)"', headers)
                    if match:
                        app_filename = match.group(1)
                        break

            if not app_filename:
                self._send_json(400, {"error": "æœªæ‰¾åˆ°æ–‡ä»¶"})
                return

            # ä½¿ç”¨æ¿€æ´»ä»“åº“çš„ registry_prefix
            from backend.config import get_active_registry

            active_registry = get_active_registry()
            base_name = active_registry.get("registry_prefix", "")
            suggested_name = generate_image_name(base_name, app_filename)
            self._send_json(200, {"suggested_imagename": suggested_name})

        except Exception as e:
            import traceback

            traceback.print_exc()
            self._send_json(500, {"error": f"ç”Ÿæˆé•œåƒåå¤±è´¥: {str(e)}"})

    def handle_save_config(self):
        try:
            content_length = int(self.headers["Content-Length"])
            body = self.rfile.read(content_length)

            boundary = self.headers["Content-Type"].split("boundary=")[1].encode()
            parts = body.split(b"--" + boundary)
            form_data = {}

            for part in parts[1:-1]:
                if b"\r\n\r\n" in part:
                    header_end = part.find(b"\r\n\r\n")
                    headers = part[:header_end].decode("utf-8", errors="ignore")
                    data = part[header_end + 4 :].rstrip(b"\r\n")

                    if 'name="' in headers:
                        try:
                            field_name = headers.split('name="')[1].split('"')[0]
                            form_data[field_name] = data.decode(
                                "utf-8", errors="ignore"
                            )
                        except:
                            continue

            config = load_config()
            new_docker_config = {
                "registry": form_data.get("registry", "docker.io").strip(),
                "registry_prefix": form_data.get("registry_prefix", "")
                .strip()
                .rstrip("/"),
                "default_push": (form_data.get("default_push") == "on"),
                "username": form_data.get("username", "").strip(),
                "password": form_data.get("password", "").strip(),
                "expose_port": (
                    int(form_data.get("expose_port", "8080"))
                    if form_data.get("expose_port", "").isdigit()
                    else 8080
                ),
                # è¿œç¨‹ Docker é…ç½®
                "use_remote": (form_data.get("use_remote") == "on"),
                "remote": {
                    "host": form_data.get("remote_host", "").strip(),
                    "port": (
                        int(form_data.get("remote_port", "2375"))
                        if form_data.get("remote_port", "").isdigit()
                        else 2375
                    ),
                    "use_tls": (form_data.get("remote_use_tls") == "on"),
                    "cert_path": form_data.get("remote_cert_path", "").strip(),
                    "verify_tls": (form_data.get("remote_verify_tls", "on") == "on"),
                },
            }

            if "docker" not in config:
                config["docker"] = {}
            config["docker"].update(new_docker_config)

            save_config(config)

            # é‡æ–°åˆå§‹åŒ– Docker æ„å»ºå™¨
            global docker_builder, DOCKER_AVAILABLE
            docker_builder = init_docker_builder()
            DOCKER_AVAILABLE = docker_builder.is_available()

            print(f"âœ… é…ç½®å·²æ›´æ–°: {config['docker']}")
            self._send_json(
                200,
                {"message": "Docker é…ç½®ä¿å­˜æˆåŠŸï¼", "docker_config": config["docker"]},
            )

        except Exception as e:
            import traceback

            traceback.print_exc()
            error_msg = str(e)
            clean_error_msg = re.sub(r"[\x00-\x1F\x7F]", " ", error_msg).strip()
            self._send_json(500, {"error": f"ä¿å­˜é…ç½®å¤±è´¥: {clean_error_msg}"})

    def _collect_template_details(self):
        """æ”¶é›†æ‰€æœ‰æ¨¡æ¿è¯¦æƒ…ï¼ˆå†…ç½® + ç”¨æˆ·è‡ªå®šä¹‰ï¼‰"""
        details = []
        templates = get_all_templates()

        for name, info in templates.items():
            try:
                stat = os.stat(info["path"])
                details.append(
                    {
                        "name": name,
                        "filename": os.path.basename(info["path"]),
                        "size": stat.st_size,
                        "updated_at": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                        "type": info["type"],  # 'builtin' æˆ– 'user'
                        "project_type": info.get(
                            "project_type", "jar"
                        ),  # é¡¹ç›®ç±»å‹ï¼šjar æˆ– nodejs
                        "editable": info["type"] == "user",  # åªæœ‰ç”¨æˆ·æ¨¡æ¿å¯ç¼–è¾‘
                    }
                )
            except OSError:
                continue

        details.sort(key=lambda item: natural_sort_key(item["name"]))
        return details

    def _extract_images_from_compose(self, compose_doc):
        images = []
        if not isinstance(compose_doc, dict):
            return images
        services = compose_doc.get("services", {})
        if isinstance(services, dict):
            for service_name, service_conf in services.items():
                if not isinstance(service_conf, dict):
                    continue
                image_ref = service_conf.get("image")
                if image_ref:
                    image_name, tag = self._split_image_reference(
                        str(image_ref).strip()
                    )
                    if image_name:
                        images.append(
                            {
                                "service": service_name,
                                "image": image_name,
                                "tag": tag,
                                "raw": image_ref,
                            }
                        )
        return images

    def _split_image_reference(self, reference: str):
        if not reference:
            return "", "latest"
        if "@" in reference:
            name, digest = reference.split("@", 1)
            return name or "", digest or "latest"
        slash_index = reference.rfind("/")
        colon_index = reference.rfind(":")
        if colon_index > slash_index:
            name = reference[:colon_index]
            tag = reference[colon_index + 1 :] or "latest"
            return name or "", tag
        return reference, "latest"

    def _resolve_template_path(self, template_name, for_write=False):
        """è§£ææ¨¡æ¿è·¯å¾„
        Args:
            template_name: æ¨¡æ¿åç§°
            for_write: æ˜¯å¦ç”¨äºå†™å…¥æ“ä½œï¼ˆæ–°å»º/ç¼–è¾‘/åˆ é™¤ï¼‰
        Returns:
            (filepath, clean_name, filename)
        """
        clean_name = (
            get_safe_filename(template_name).replace(".Dockerfile", "").strip("_-. ")
        )
        if not clean_name:
            raise ValueError("æ¨¡æ¿åç§°æ— æ•ˆ")
        filename = f"{clean_name}.Dockerfile"

        # å†™å…¥æ“ä½œï¼šåªèƒ½æ“ä½œç”¨æˆ·æ¨¡æ¿ç›®å½•
        if for_write:
            filepath = os.path.join(USER_TEMPLATES_DIR, filename)
        else:
            # è¯»å–æ“ä½œï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æ¨¡æ¿ï¼Œå¦åˆ™ä½¿ç”¨å†…ç½®æ¨¡æ¿
            filepath = get_template_path(clean_name)
            if not filepath:
                # æ¨¡æ¿ä¸å­˜åœ¨ï¼Œè¿”å›ç”¨æˆ·æ¨¡æ¿è·¯å¾„ï¼ˆç”¨äºåç»­åˆ¤æ–­ï¼‰
                filepath = os.path.join(USER_TEMPLATES_DIR, filename)

        return filepath, clean_name, filename

    def _read_json_body(self):
        try:
            length = int(self.headers.get("Content-Length", 0))
        except (TypeError, ValueError):
            length = 0
        raw = self.rfile.read(length) if length else b""
        if not raw:
            return {}
        try:
            return json.loads(raw.decode("utf-8"))
        except json.JSONDecodeError as e:
            raise ValueError(f"è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆ JSON: {e}")

    def handle_parse_compose(self):
        try:
            data = self._read_json_body()
        except ValueError as ve:
            self._send_json(400, {"error": str(ve)})
            return

        content = (data.get("content") or "").strip()
        if not content:
            self._send_json(400, {"error": "compose å†…å®¹ä¸èƒ½ä¸ºç©º"})
            return

        try:
            documents = list(yaml.safe_load_all(content))
        except yaml.YAMLError as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(
                400, {"error": f"è§£æ YAML å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"}
            )
            return

        images = []
        seen = set()
        for doc in documents:
            for item in self._extract_images_from_compose(doc):
                key = f"{item['image']}:{item['tag']}"
                if key in seen:
                    continue
                seen.add(key)
                images.append(item)

        self._send_json(200, {"images": images})

    def handle_create_template(self):
        try:
            data = self._read_json_body()
            name = (data.get("name") or "").strip()
            content = data.get("content")
            project_type = (data.get("project_type") or "jar").strip()

            if not name:
                self._send_json(400, {"error": "æ¨¡æ¿åç§°ä¸èƒ½ä¸ºç©º"})
                return
            if not content:
                self._send_json(400, {"error": "æ¨¡æ¿å†…å®¹ä¸èƒ½ä¸ºç©º"})
                return

            # éªŒè¯é¡¹ç›®ç±»å‹æ ¼å¼ï¼šåªå…è®¸å°å†™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
            if not re.match(r"^[a-z0-9_-]+$", project_type):
                self._send_json(
                    400, {"error": "é¡¹ç›®ç±»å‹åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦"}
                )
                return

            # ä½¿ç”¨é¡¹ç›®ç±»å‹å­ç›®å½•ä¿å­˜
            filepath = get_user_template_path(name, project_type)
            if os.path.exists(filepath):
                self._send_json(
                    400, {"error": f"ç”¨æˆ·æ¨¡æ¿ä¸­å·²å­˜åœ¨åŒåæ¨¡æ¿ï¼ˆ{project_type}ï¼‰"}
                )
                return

            # å†™å…¥æ–‡ä»¶
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)

            self._send_json(
                201,
                {
                    "message": f"æ¨¡æ¿åˆ›å»ºæˆåŠŸï¼ˆä¿å­˜åˆ°ç”¨æˆ·æ¨¡æ¿/{project_type}/ç›®å½•ï¼‰",
                    "template": {
                        "name": name,
                        "project_type": project_type,
                        "filename": os.path.basename(filepath),
                    },
                },
            )
        except ValueError as ve:
            self._send_json(400, {"error": str(ve)})
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(500, {"error": f"åˆ›å»ºæ¨¡æ¿å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"})

    def handle_update_template(self):
        try:
            data = self._read_json_body()
            original_name = (
                data.get("original_name") or data.get("name") or ""
            ).strip()
            new_name = (data.get("name") or "").strip()
            content = data.get("content")
            project_type = (data.get("project_type") or "").strip()

            if not original_name:
                self._send_json(400, {"error": "ç¼ºå°‘åŸå§‹æ¨¡æ¿åç§°"})
                return
            if content is None:
                self._send_json(400, {"error": "æ¨¡æ¿å†…å®¹ä¸èƒ½ä¸ºç©º"})
                return

            # æ£€æŸ¥åŸæ¨¡æ¿æ˜¯å¦å­˜åœ¨
            templates = get_all_templates()
            if original_name not in templates:
                self._send_json(404, {"error": "åŸæ¨¡æ¿ä¸å­˜åœ¨"})
                return

            original_template = templates[original_name]
            is_builtin = original_template["type"] == "builtin"
            original_project_type = original_template["project_type"]

            # ä½¿ç”¨æä¾›çš„é¡¹ç›®ç±»å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸæ¨¡æ¿çš„é¡¹ç›®ç±»å‹
            target_project_type = project_type or original_project_type

            # éªŒè¯é¡¹ç›®ç±»å‹æ ¼å¼
            if target_project_type and not re.match(
                r"^[a-z0-9_-]+$", target_project_type
            ):
                self._send_json(
                    400, {"error": "é¡¹ç›®ç±»å‹åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦"}
                )
                return

            target_name = new_name or original_name

            # å¦‚æœæ˜¯å†…ç½®æ¨¡æ¿ï¼Œåªèƒ½åœ¨ç”¨æˆ·ç›®å½•åˆ›å»ºåŒåè¦†ç›–
            if is_builtin:
                if new_name and new_name != original_name:
                    self._send_json(
                        403,
                        {
                            "error": "å†…ç½®æ¨¡æ¿ä¸èƒ½é‡å‘½åï¼Œåªèƒ½åœ¨ç”¨æˆ·æ¨¡æ¿ä¸­åˆ›å»ºåŒåæ¨¡æ¿è¿›è¡Œè¦†ç›–"
                        },
                    )
                    return
                # å†…ç½®æ¨¡æ¿ä¸å…è®¸ä¿®æ”¹é¡¹ç›®ç±»å‹
                if target_project_type != original_project_type:
                    self._send_json(
                        403,
                        {"error": "å†…ç½®æ¨¡æ¿çš„é¡¹ç›®ç±»å‹ä¸å¯ä¿®æ”¹"},
                    )
                    return
                # åœ¨ç”¨æˆ·ç›®å½•çš„å¯¹åº”é¡¹ç›®ç±»å‹å­ç›®å½•ä¸­åˆ›å»º
                dst_path = get_user_template_path(target_name, target_project_type)
            else:
                # ç”¨æˆ·æ¨¡æ¿å¯ä»¥ç¼–è¾‘å’Œé‡å‘½å
                src_path = original_template["path"]
                dst_path = get_user_template_path(target_name, target_project_type)

                # æ£€æŸ¥ç›®æ ‡è·¯å¾„æ˜¯å¦å·²å­˜åœ¨ï¼ˆä¸”ä¸æ˜¯åŸæ–‡ä»¶ï¼‰
                if dst_path != src_path and os.path.exists(dst_path):
                    self._send_json(400, {"error": "ç›®æ ‡æ¨¡æ¿åç§°å·²å­˜åœ¨"})
                    return

            # å†™å…¥æ–°å†…å®¹
            tmp_path = dst_path + ".tmp"
            with open(tmp_path, "w", encoding="utf-8") as f:
                f.write(content)
            os.replace(tmp_path, dst_path)

            # å¦‚æœæ˜¯ç”¨æˆ·æ¨¡æ¿çš„é‡å‘½åæˆ–é¡¹ç›®ç±»å‹ä¿®æ”¹ï¼Œåˆ é™¤åŸæ–‡ä»¶
            if not is_builtin and dst_path != original_template["path"]:
                try:
                    os.remove(original_template["path"])
                except OSError:
                    pass  # å¦‚æœåˆ é™¤å¤±è´¥ä¹Ÿä¸å½±å“

            # æ„å»ºæˆåŠŸæ¶ˆæ¯
            if is_builtin:
                message = "æ¨¡æ¿å·²ä¿å­˜åˆ°ç”¨æˆ·ç›®å½•"
            elif target_project_type != original_project_type:
                message = f"æ¨¡æ¿å·²æ›´æ–°å¹¶ç§»åŠ¨åˆ° {target_project_type} ç›®å½•"
            else:
                message = "æ¨¡æ¿æ›´æ–°æˆåŠŸ"

            self._send_json(
                200,
                {
                    "message": message,
                    "template": {
                        "name": target_name,
                        "project_type": target_project_type,
                        "filename": os.path.basename(dst_path),
                    },
                },
            )
        except ValueError as ve:
            self._send_json(400, {"error": str(ve)})
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(500, {"error": f"æ›´æ–°æ¨¡æ¿å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"})

    def handle_delete_template(self):
        try:
            data = self._read_json_body()
            name = (data.get("name") or "").strip()
            if not name:
                self._send_json(400, {"error": "æ¨¡æ¿åç§°ä¸èƒ½ä¸ºç©º"})
                return

            # æ£€æŸ¥æ˜¯å¦ä¸ºå†…ç½®æ¨¡æ¿
            templates = get_all_templates()
            if name in templates and templates[name]["type"] == "builtin":
                self._send_json(
                    403,
                    {"error": "å†…ç½®æ¨¡æ¿ä¸å¯åˆ é™¤ï¼Œè¯·åœ¨ç”¨æˆ·æ¨¡æ¿ä¸­åˆ›å»ºåŒåæ¨¡æ¿è¿›è¡Œè¦†ç›–"},
                )
                return

            filepath, clean_name, filename = self._resolve_template_path(
                name, for_write=True
            )
            if not os.path.exists(filepath):
                self._send_json(404, {"error": "æ¨¡æ¿ä¸å­˜åœ¨"})
                return
            os.remove(filepath)
            self._send_json(200, {"message": "æ¨¡æ¿å·²åˆ é™¤"})
        except ValueError as ve:
            self._send_json(400, {"error": str(ve)})
        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            self._send_json(500, {"error": f"åˆ é™¤æ¨¡æ¿å¤±è´¥: {clean_msg or 'æœªçŸ¥é”™è¯¯'}"})

    def handle_upload(self):
        content_length = int(self.headers["Content-Length"])
        body = self.rfile.read(content_length)

        try:
            boundary = self.headers["Content-Type"].split("boundary=")[1].encode()
            parts = body.split(b"--" + boundary)
            form_data = {}
            file_data = None
            file_name = None

            for part in parts[1:-1]:
                if b"\r\n\r\n" not in part:
                    continue
                header_end = part.find(b"\r\n\r\n")
                headers = part[:header_end].decode("utf-8", errors="ignore")
                data = part[header_end + 4 :].rstrip(b"\r\n")

                if "filename=" in headers:
                    try:
                        filename = headers.split("filename=")[1].split('"')[1]
                        # æ”¯æŒå¤šç§æ–‡ä»¶ç±»å‹ï¼šjar, zip, tar, tar.gz
                        if filename.endswith(
                            (".jar", ".zip", ".tar", ".tar.gz", ".tgz")
                        ):
                            file_data = data
                            file_name = filename
                            form_data["original_filename"] = filename
                    except Exception as e:
                        print(f"âš ï¸ è§£ææ–‡ä»¶åå¤±è´¥: {e}")
                        continue
                else:
                    try:
                        field_name = headers.split('name="')[1].split('"')[0]
                        form_data[field_name] = data.decode("utf-8", errors="ignore")
                    except Exception as e:
                        print(f"âš ï¸ è§£æå­—æ®µå¤±è´¥: {e}")
                        continue

            if not file_data:
                self._send_json(400, {"error": "æœªä¸Šä¼ æ–‡ä»¶"})
                return

            # è·å–é¡¹ç›®ç±»å‹
            project_type = form_data.get("project_type", "jar")  # jar æˆ– nodejs

            # ç”ŸæˆåŸºç¡€åç§°
            base_name = file_name
            for ext in [".jar", ".zip", ".tar.gz", ".tgz", ".tar"]:
                if base_name.endswith(ext):
                    base_name = base_name[: -len(ext)]
                    break

            image_name = form_data.get("imagename") or f"myapp/{base_name}"
            tag = form_data.get("tag") or "latest"
            should_push = form_data.get("push") == "on"
            selected_template = form_data.get("template") or (
                "node20" if project_type == "nodejs" else "dragonwell17"
            )

            # ğŸ‘‡ å¯åŠ¨åå°æ„å»ºï¼Œç«‹å³è¿”å› build_id
            build_manager = BuildManager()
            build_id = build_manager.start_build(
                file_data=file_data,
                image_name=image_name,
                tag=tag,
                should_push=should_push,
                selected_template=selected_template,
                original_filename=file_name,
                project_type=project_type,
            )

            self._send_json(
                200,
                {
                    "build_id": build_id,
                    "message": "æ„å»ºä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·é€šè¿‡ WebSocket è®¢é˜…æ—¥å¿—",
                },
            )

        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            print(f"âŒ ä¸Šä¼ å¤„ç†å¤±è´¥: {clean_msg}")
            import traceback

            traceback.print_exc()
            self._send_json(500, {"error": f"æœåŠ¡å™¨é”™è¯¯: {clean_msg}"})

    def log_message(self, format, *args):
        return  # é™éŸ³æ—¥å¿—


class BuildManager:
    _instance_lock = threading.Lock()
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._init()
        return cls._instance

    def _init(self):
        self.logs = defaultdict(deque)  # build_id -> deque[str] (ä¿ç•™ç”¨äºå…¼å®¹)
        self.lock = threading.Lock()
        self.tasks = {}  # build_id -> Thread (ä¿ç•™ç”¨äºå…¼å®¹)
        self.task_manager = BuildTaskManager()  # ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨

    def start_build(
        self,
        file_data: bytes,
        image_name: str,
        tag: str,
        should_push: bool,
        selected_template: str,
        original_filename: str,
        project_type: str = "jar",
        template_params: dict = None,
        push_registry: str = None,  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼Œå®é™…ä¸å†ä½¿ç”¨
        extract_archive: bool = True,  # æ˜¯å¦è§£å‹å‹ç¼©åŒ…ï¼ˆé»˜è®¤è§£å‹ï¼‰
    ):
        # åˆ›å»ºä»»åŠ¡
        task_id = self.task_manager.create_task(
            task_type="build",
            image_name=image_name,
            tag=tag,
            should_push=should_push,
            selected_template=selected_template,
            original_filename=original_filename,
            project_type=project_type,
            template_params=template_params or {},
            push_registry=push_registry,
            extract_archive=extract_archive,
        )

        thread = threading.Thread(
            target=self._build_task,
            args=(
                task_id,
                file_data,
                image_name,
                tag,
                should_push,
                selected_template,
                original_filename,
                project_type,
                template_params or {},
                push_registry,
                extract_archive,
            ),
            daemon=True,
        )
        thread.start()
        with self.lock:
            self.tasks[task_id] = thread
        return task_id

    def _build_task(
        self,
        task_id: str,
        file_data: bytes,
        image_name: str,
        tag: str,
        should_push: bool,
        selected_template: str,
        original_filename: str,
        project_type: str = "jar",
        template_params: dict = None,
        push_registry: str = None,  # å·²åºŸå¼ƒï¼Œä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼Œå®é™…ä¸å†ä½¿ç”¨
        extract_archive: bool = True,  # æ˜¯å¦è§£å‹å‹ç¼©åŒ…ï¼ˆé»˜è®¤è§£å‹ï¼‰
    ):
        full_tag = f"{image_name}:{tag}"
        # ä½¿ç”¨ task_id ä½œä¸ºæ„å»ºä¸Šä¸‹æ–‡ç›®å½•åçš„ä¸€éƒ¨åˆ†ï¼Œé¿å…å†²çª
        build_context = os.path.join(
            BUILD_DIR, f"{image_name.replace('/', '_')}_{task_id[:8]}"
        )

        def log(msg: str):
            """æ·»åŠ æ—¥å¿—ï¼Œè‡ªåŠ¨ç¡®ä¿ä»¥æ¢è¡Œç¬¦ç»“å°¾"""
            if not msg.endswith("\n"):
                msg = msg + "\n"
            # ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨è®°å½•æ—¥å¿—
            self.task_manager.add_log(task_id, msg)
            # ä¿ç•™æ—§çš„æ—¥å¿—ç³»ç»Ÿç”¨äºå…¼å®¹
            with self.lock:
                self.logs[task_id].append(msg)

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        self.task_manager.update_task_status(task_id, "running")

        def do_extract_archive(file_path: str, extract_to: str):
            """è§£å‹å‹ç¼©æ–‡ä»¶"""
            try:
                if file_path.endswith(".zip"):
                    log("ğŸ“¦ è§£å‹ ZIP æ–‡ä»¶...\n")
                    with zipfile.ZipFile(file_path, "r") as zip_ref:
                        zip_ref.extractall(extract_to)
                elif file_path.endswith((".tar.gz", ".tgz")):
                    log("ğŸ“¦ è§£å‹ TAR.GZ æ–‡ä»¶...\n")
                    with tarfile.open(file_path, "r:gz") as tar_ref:
                        tar_ref.extractall(extract_to)
                elif file_path.endswith(".tar"):
                    log("ğŸ“¦ è§£å‹ TAR æ–‡ä»¶...\n")
                    with tarfile.open(file_path, "r") as tar_ref:
                        tar_ref.extractall(extract_to)
                else:
                    return False
                log("âœ… è§£å‹å®Œæˆ\n")

                # åˆ—å‡ºè§£å‹åçš„ç›®å½•æ¦‚å†µå’Œæ–‡ä»¶
                try:
                    log("ğŸ“‚ è§£å‹åç›®å½•æ¦‚å†µï¼š\n")
                    if os.path.exists(extract_to):
                        # ç»Ÿè®¡æ ¹ç›®å½•ä¸‹çš„ç›´æ¥å†…å®¹
                        root_items = os.listdir(extract_to)
                        dirs = []
                        files = []
                        total_size = 0
                        total_files = 0

                        for item in root_items:
                            item_path = os.path.join(extract_to, item)
                            if os.path.isdir(item_path):
                                dirs.append(item)
                            elif os.path.isfile(item_path):
                                files.append(item)

                        # é€’å½’ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶å¤§å°å’Œæ•°é‡
                        for root, dirs_list, files_list in os.walk(extract_to):
                            for f in files_list:
                                file_path_full = os.path.join(root, f)
                                if os.path.isfile(file_path_full):
                                    total_size += os.path.getsize(file_path_full)
                                    total_files += 1

                        # æ ¼å¼åŒ–å¤§å°
                        if total_size < 1024:
                            size_str = f"{total_size} B"
                        elif total_size < 1024 * 1024:
                            size_str = f"{total_size / 1024:.2f} KB"
                        else:
                            size_str = f"{total_size / (1024 * 1024):.2f} MB"

                        log(f"  ğŸ“ æ ¹ç›®å½•ä¸‹ç›®å½•æ•°: {len(dirs)}\n")
                        log(f"  ğŸ“„ æ ¹ç›®å½•ä¸‹æ–‡ä»¶æ•°: {len(files)}\n")
                        log(f"  ğŸ“Š æ€»æ–‡ä»¶æ•°: {total_files}\n")
                        log(f"  ğŸ’¾ æ€»å¤§å°: {size_str}\n")

                        if dirs:
                            log("  ğŸ“ æ ¹ç›®å½•åˆ—è¡¨ï¼š\n")
                            for d in sorted(dirs)[:20]:  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                                log(f"    - {d}/\n")
                            if len(dirs) > 20:
                                log(f"    ... è¿˜æœ‰ {len(dirs) - 20} ä¸ªç›®å½•\n")

                        if files:
                            log("  ğŸ“„ æ ¹ç›®å½•æ–‡ä»¶åˆ—è¡¨ï¼š\n")
                            for f in sorted(files)[:30]:  # æœ€å¤šæ˜¾ç¤º30ä¸ª
                                file_path_full = os.path.join(extract_to, f)
                                if os.path.isfile(file_path_full):
                                    size = os.path.getsize(file_path_full)
                                    if size < 1024:
                                        f_size_str = f"{size} B"
                                    elif size < 1024 * 1024:
                                        f_size_str = f"{size / 1024:.2f} KB"
                                    else:
                                        f_size_str = f"{size / (1024 * 1024):.2f} MB"
                                    log(f"    - {f} ({f_size_str})\n")
                            if len(files) > 30:
                                log(f"    ... è¿˜æœ‰ {len(files) - 30} ä¸ªæ–‡ä»¶\n")
                except Exception as e:
                    log(f"âš ï¸  æ— æ³•åˆ—å‡ºç›®å½•å†…å®¹: {str(e)}\n")

                return True
            except Exception as e:
                log(f"âŒ è§£å‹å¤±è´¥: {str(e)}\n")
                return False

        try:
            log(f"ğŸ“¦ å¼€å§‹å¤„ç†ä¸Šä¼ : {original_filename}\n")
            log(f"ğŸ“ ä¸Šä¼ çš„æ–‡ä»¶å: {original_filename}ï¼ˆåœ¨æ„å»ºä¸Šä¸‹æ–‡ä¸­å·²ç»Ÿä¸€å¤„ç†ï¼‰\n")
            log(f"ğŸ·ï¸ é•œåƒå: {full_tag}\n")
            log(f"ğŸ§± æ¨¡æ¿: {selected_template}\n")
            log(f"ğŸ“‚ é¡¹ç›®ç±»å‹: {project_type}\n")

            # === æ¨¡æ‹Ÿæ¨¡å¼ ===
            if not DOCKER_AVAILABLE:
                config = load_config()
                os.makedirs(build_context, exist_ok=True)

                # åˆ¤æ–­æ–‡ä»¶ç±»å‹å¹¶å¤„ç†ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
                is_jar = original_filename.lower().endswith(".jar")
                is_archive = any(
                    original_filename.lower().endswith(ext)
                    for ext in [".zip", ".tar", ".tar.gz", ".tgz"]
                )

                if is_archive:
                    # å‹ç¼©åŒ…ï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦è§£å‹
                    file_path = os.path.join(build_context, original_filename)
                    with open(file_path, "wb") as f:
                        f.write(file_data)

                    if extract_archive:
                        # ç”¨æˆ·é€‰æ‹©è§£å‹
                        log(
                            f"ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ£€æµ‹åˆ°å‹ç¼©åŒ…: {original_filename}ï¼Œå¼€å§‹è§£å‹...\n"
                        )
                        if do_extract_archive(file_path, build_context):
                            log(
                                f"ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šå‹ç¼©åŒ…å·²è§£å‹åˆ°æ„å»ºä¸Šä¸‹æ–‡æ ¹ç›®å½•ï¼ˆåŸå§‹æ–‡ä»¶å: {original_filename}ï¼‰\n"
                            )
                            try:
                                os.remove(file_path)
                            except:
                                pass
                        else:
                            log("âš ï¸ æ¨¡æ‹Ÿæ¨¡å¼ï¼šè§£å‹å¤±è´¥ï¼ˆä¸æ”¯æŒçš„æ ¼å¼ï¼‰\n")
                    else:
                        # ç”¨æˆ·é€‰æ‹©ä¸è§£å‹ï¼Œä¿æŒå‹ç¼©åŒ…åŸæ ·
                        log(
                            f"ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šå‹ç¼©åŒ…å·²ä¿å­˜: {original_filename}ï¼ˆæœªè§£å‹ï¼Œä¿æŒåŸæ ·ï¼‰\n"
                        )
                elif is_jar:
                    # JAR æ–‡ä»¶ï¼šä¿å­˜ä¸ºå›ºå®šåç§° app.jar
                    with open(os.path.join(build_context, "app.jar"), "wb") as f:
                        f.write(file_data)
                    log(
                        f"ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šJAR æ–‡ä»¶å·²ä¿å­˜ä¸º: app.jarï¼ˆåŸå§‹æ–‡ä»¶å: {original_filename}ï¼‰\n"
                    )
                else:
                    # å…¶ä»–æ–‡ä»¶ï¼šä¿æŒåŸæ–‡ä»¶å
                    file_path = os.path.join(build_context, original_filename)
                    with open(file_path, "wb") as f:
                        f.write(file_data)
                    log(
                        f"ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ–‡ä»¶å·²ä¿å­˜: {original_filename}ï¼ˆä¿æŒåŸæ–‡ä»¶åï¼‰\n"
                    )

                for line in [
                    "ğŸ§ª æ¨¡æ‹Ÿæ¨¡å¼ï¼šDocker æœåŠ¡ä¸å¯ç”¨\n",
                    f"Step 1/4 : FROM {'node:20-alpine' if project_type == 'nodejs' else 'openjdk:17-jre-slim'} (æ¨¡æ‹Ÿ)\n",
                    "Step 2/4 : COPY . . (æ¨¡æ‹Ÿ)\n",
                    "Step 3/4 : WORKDIR /app (æ¨¡æ‹Ÿ)\n",
                    f"Step 4/4 : CMD (æ¨¡æ‹Ÿ)\n",
                    f"âœ… æ¨¡æ‹Ÿæ„å»ºæˆåŠŸ: {full_tag}\n",
                ]:
                    log(line)

                if should_push:
                    # æ¨é€æ—¶ç»Ÿä¸€ä½¿ç”¨æ¿€æ´»çš„registry
                    from backend.config import get_active_registry

                    push_registry_config = get_active_registry()

                    log("ğŸš€ å¼€å§‹æ¨¡æ‹Ÿæ¨é€...\n")
                    log(
                        f"ğŸ¯ ä½¿ç”¨æ¿€æ´»ä»“åº“: {push_registry_config.get('name', 'Unknown')}\n"
                    )
                    username = push_registry_config.get("username", None)
                    log(f"ğŸš€ è´¦å·: {username}\n")
                    for i in range(1, 4):
                        log(f"ğŸ“¡ Pushing layer {i}/3...\n")
                    log(
                        f"âœ… æ¨¡æ‹Ÿæ¨é€å®Œæˆåˆ° {push_registry_config.get('registry', 'Unknown')}\n"
                    )
                else:
                    log("ğŸš€ æ¨¡æ‹Ÿæ¨é€è·³è¿‡ï¼ˆæœªå¯ç”¨æ¨é€ï¼‰\n")

                log("\nâœ…âœ…âœ… æ‰€æœ‰æ“ä½œå·²å®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰âœ…âœ…âœ…\n")
                return

            # === çœŸå®æ„å»º ===
            os.makedirs(build_context, exist_ok=True)

            # åˆ¤æ–­æ–‡ä»¶ç±»å‹å¹¶å¤„ç†
            is_jar = original_filename.lower().endswith(".jar")
            is_archive = any(
                original_filename.lower().endswith(ext)
                for ext in [".zip", ".tar", ".tar.gz", ".tgz"]
            )

            if is_archive:
                # å‹ç¼©åŒ…ï¼šæ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šæ˜¯å¦è§£å‹
                file_path = os.path.join(build_context, original_filename)
                with open(file_path, "wb") as f:
                    f.write(file_data)

                if extract_archive:
                    # ç”¨æˆ·é€‰æ‹©è§£å‹
                    log(f"ğŸ“¦ æ£€æµ‹åˆ°å‹ç¼©åŒ…: {original_filename}ï¼Œå¼€å§‹è§£å‹...\n")
                    if do_extract_archive(file_path, build_context):
                        # è§£å‹æˆåŠŸï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        log(
                            f"âœ… å‹ç¼©åŒ…å·²è§£å‹åˆ°æ„å»ºä¸Šä¸‹æ–‡æ ¹ç›®å½•ï¼ˆåŸå§‹æ–‡ä»¶å: {original_filename}ï¼‰\n"
                        )
                        try:
                            os.remove(file_path)
                        except:
                            pass
                    else:
                        log(f"âŒ è§£å‹å¤±è´¥: {original_filename}\n")
                        return
                else:
                    # ç”¨æˆ·é€‰æ‹©ä¸è§£å‹ï¼Œä¿æŒå‹ç¼©åŒ…åŸæ ·
                    log(f"ğŸ“¦ å‹ç¼©åŒ…å·²ä¿å­˜: {original_filename}ï¼ˆæœªè§£å‹ï¼Œä¿æŒåŸæ ·ï¼‰\n")
            elif is_jar:
                # JAR æ–‡ä»¶ï¼šä¿å­˜ä¸ºå›ºå®šåç§° app.jar
                jar_path = os.path.join(build_context, "app.jar")
                with open(jar_path, "wb") as f:
                    f.write(file_data)
                log(
                    f"âœ… JAR æ–‡ä»¶å·²ä¿å­˜ä¸º: app.jarï¼ˆåŸå§‹æ–‡ä»¶å: {original_filename}ï¼‰\n"
                )
            else:
                # å…¶ä»–æ–‡ä»¶ï¼šä¿æŒåŸæ–‡ä»¶å
                file_path = os.path.join(build_context, original_filename)
                with open(file_path, "wb") as f:
                    f.write(file_data)
                log(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {original_filename}ï¼ˆä¿æŒåŸæ–‡ä»¶åï¼‰\n")

            # è·å–æ¨¡æ¿è·¯å¾„ï¼ˆä¼˜å…ˆç”¨æˆ·æ¨¡æ¿ï¼Œå¦åˆ™ä½¿ç”¨å†…ç½®æ¨¡æ¿ï¼‰
            template_file = get_template_path(selected_template, project_type)
            if not template_file:
                log(f"âŒ æ¨¡æ¿ä¸å­˜åœ¨: {selected_template}\n")
                return

            with open(template_file, "r", encoding="utf-8") as f:
                dockerfile_content = f.read()

            # æ›¿æ¢æ¨¡æ¿å˜é‡
            config = load_config()

            # å‡†å¤‡å˜é‡æ›¿æ¢å­—å…¸
            template_vars = template_params or {}

            # è‡ªåŠ¨æ·»åŠ ä¸Šä¼ çš„æ–‡ä»¶åå˜é‡ï¼ˆä¾›æ¨¡æ¿åˆ¤æ–­ä½¿ç”¨ï¼‰
            template_vars["UPLOADED_FILENAME"] = original_filename

            # å¦‚æœæ²¡æœ‰ä¼ å…¥ EXPOSE_PORTï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
            if "EXPOSE_PORT" not in template_vars:
                template_vars["EXPOSE_PORT"] = str(
                    config.get("docker", {}).get("expose_port", 8080)
                )

            # æ›¿æ¢æ‰€æœ‰å˜é‡
            from backend.template_parser import replace_template_variables

            try:
                dockerfile_content = replace_template_variables(
                    dockerfile_content, template_vars
                )
            except ValueError as e:
                log(f"âŒ æ¨¡æ¿å˜é‡æ›¿æ¢å¤±è´¥: {e}\n")
                return

            with open(
                os.path.join(build_context, "Dockerfile"), "w", encoding="utf-8"
            ) as f:
                f.write(dockerfile_content)

            log(f"\nğŸš€ å¼€å§‹æ„å»ºé•œåƒ: {full_tag}\n")
            log(f"ğŸ³ ä½¿ç”¨æ„å»ºå™¨: {docker_builder.get_connection_info()}\n")

            # æ‹‰å–åŸºç¡€é•œåƒæ—¶ï¼ŒDocker ä¼šé»˜è®¤åˆ°æ‰€æœ‰ä»“åº“ä¸­å¯»æ‰¾ï¼Œä¸éœ€è¦æŒ‡å®šè®¤è¯ä»“åº“

            build_stream = docker_builder.build_image(
                path=build_context, tag=full_tag, pull=True  # è‡ªåŠ¨æ‹‰å–åŸºç¡€é•œåƒ
            )
            build_succeeded = False
            last_error = None

            for chunk in build_stream:
                if "stream" in chunk:
                    log(f"ğŸ—ï¸  {chunk['stream']}")
                elif "error" in chunk:
                    last_error = chunk["error"]
                    log(f"\nğŸ”¥ [DOCKER ERROR]: {last_error}\n")
                elif "errorDetail" in chunk:
                    err_msg = chunk["errorDetail"].get("message", "Unknown")
                    last_error = err_msg
                    log(f"\nğŸ’¥ [ERROR DETAIL]: {err_msg}\n")
                elif "aux" in chunk and "ID" in chunk["aux"]:
                    build_succeeded = True

            if not build_succeeded:
                log(f"\nâŒ æ„å»ºå¤±è´¥ï¼æœ€åé”™è¯¯: {last_error or 'æœªçŸ¥é”™è¯¯'}\n")
                return

            log(f"\nâœ… é•œåƒæ„å»ºæˆåŠŸ: {full_tag}\n")

            if should_push:
                # æ¨é€æ—¶ç›´æ¥ä½¿ç”¨æ„å»ºå¥½çš„é•œåƒåï¼Œæ ¹æ®é•œåƒåæ‰¾åˆ°å¯¹åº”çš„registryè·å–è®¤è¯ä¿¡æ¯
                from backend.config import get_active_registry, get_all_registries

                # æ ¹æ®é•œåƒåæ‰¾åˆ°å¯¹åº”çš„registryé…ç½®
                def find_matching_registry_for_push(image_name):
                    """æ ¹æ®é•œåƒåæ‰¾åˆ°åŒ¹é…çš„registryé…ç½®"""
                    # å¦‚æœé•œåƒååŒ…å«æ–œæ ï¼Œæå–registryéƒ¨åˆ†
                    parts = image_name.split("/")
                    if len(parts) >= 2 and "." in parts[0]:
                        # é•œåƒåæ ¼å¼: registry.com/namespace/image
                        image_registry = parts[0]
                        all_registries = get_all_registries()
                        for reg in all_registries:
                            reg_address = reg.get("registry", "")
                            if reg_address and (
                                image_registry == reg_address
                                or image_registry.startswith(reg_address)
                                or reg_address.startswith(image_registry)
                            ):
                                return reg
                    return None

                # å°è¯•æ ¹æ®é•œåƒåæ‰¾åˆ°åŒ¹é…çš„registry
                push_registry_config = find_matching_registry_for_push(image_name)
                if not push_registry_config:
                    # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨æ¿€æ´»çš„registry
                    push_registry_config = get_active_registry()
                    log(
                        f"\nâš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„registryé…ç½®ï¼Œä½¿ç”¨æ¿€æ´»ä»“åº“: {push_registry_config.get('name', 'Unknown')}\n"
                    )
                else:
                    log(
                        f"\nğŸ¯ æ‰¾åˆ°åŒ¹é…çš„registryé…ç½®: {push_registry_config.get('name', 'Unknown')}\n"
                    )

                log(f"ğŸ“¤ å¼€å§‹æ¨é€é•œåƒ: {full_tag}\n")

                # ç›´æ¥ä½¿ç”¨æ„å»ºæ—¶çš„é•œåƒå
                push_repository = image_name
                log(f"ğŸ“¦ æ¨é€é•œåƒ: {full_tag}\n")

                push_username = push_registry_config.get("username")
                push_password = push_registry_config.get("password")
                push_registry_host = push_registry_config.get("registry", "")

                log(
                    f"ğŸ” Registryé…ç½® - åœ°å€: {push_registry_host}, ç”¨æˆ·å: {push_username}, å¯†ç : {'***' if push_password else '(æœªé…ç½®)'}\n"
                )

                auth_config = None
                if push_username and push_password:
                    # æ„å»ºauth_configï¼ŒåŒ…å«registryä¿¡æ¯
                    # docker-pyçš„push APIéœ€è¦serveraddresså­—æ®µæ¥æŒ‡å®šregistry
                    auth_config = {
                        "username": push_username,
                        "password": push_password,
                    }
                    # å¯¹äºédocker.ioçš„registryï¼Œå¿…é¡»è®¾ç½®serveraddress
                    if push_registry_host:
                        if push_registry_host != "docker.io":
                            auth_config["serveraddress"] = push_registry_host
                        else:
                            # docker.ioä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®
                            auth_config["serveraddress"] = "https://index.docker.io/v1/"
                    else:
                        # å¦‚æœæ²¡æœ‰registry_hostï¼Œé»˜è®¤ä½¿ç”¨docker.io
                        auth_config["serveraddress"] = "https://index.docker.io/v1/"

                    log(f"âœ… å·²é…ç½®è®¤è¯ä¿¡æ¯\n")
                    log(
                        f"ğŸ” Authé…ç½®: username={push_username}, serveraddress={auth_config.get('serveraddress', 'docker.io')}\n"
                    )

                    # æ¨é€å‰å…ˆç™»å½•åˆ°registryï¼ˆé‡è¦ï¼šç¡®ä¿è®¤è¯ç”Ÿæ•ˆï¼‰
                    try:
                        if hasattr(docker_builder, "client") and docker_builder.client:
                            # å¯¹äºé˜¿é‡Œäº‘ç­‰registryï¼Œéœ€è¦ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„registryåœ°å€
                            login_registry = (
                                push_registry_host
                                if push_registry_host
                                and push_registry_host != "docker.io"
                                else None
                            )
                            log(
                                f"ğŸ”‘ æ­£åœ¨ç™»å½•åˆ°registry: {login_registry or 'docker.io'}\n"
                            )
                            log(f"ğŸ”‘ ç”¨æˆ·å: {push_username}\n")

                            # æ‰§è¡Œç™»å½•
                            login_result = docker_builder.client.login(
                                username=push_username,
                                password=push_password,
                                registry=login_registry,
                            )
                            log(f"âœ… ç™»å½•æˆåŠŸ: {login_result}\n")
                        else:
                            log(f"âš ï¸  Dockerå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡ç™»å½•\n")
                    except Exception as login_error:
                        error_msg = str(login_error)
                        log(f"âŒ ç™»å½•å¤±è´¥: {error_msg}\n")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                        if (
                            "401" in error_msg
                            or "Unauthorized" in error_msg
                            or "unauthorized" in error_msg
                        ):
                            log(f"âš ï¸  è®¤è¯å¤±è´¥ï¼Œå¯èƒ½çš„åŸå› ï¼š\n")
                            log(f"   1. ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®\n")
                            log(f"   2. å¯¹äºé˜¿é‡Œäº‘registryï¼Œè¯·ç¡®è®¤ï¼š\n")
                            log(
                                f"      - ç”¨æˆ·åï¼šä½¿ç”¨é˜¿é‡Œäº‘è´¦å·æˆ–ç‹¬ç«‹çš„é•œåƒä»“åº“ç”¨æˆ·å\n"
                            )
                            log(f"      - å¯†ç ï¼šä½¿ç”¨é˜¿é‡Œäº‘è´¦å·å¯†ç æˆ–é•œåƒä»“åº“ç‹¬ç«‹å¯†ç \n")
                            log(f"      - å¦‚æœä½¿ç”¨è®¿é—®ä»¤ç‰Œï¼Œè¯·ç¡®è®¤ä»¤ç‰Œæœªè¿‡æœŸ\n")
                            log(f"   3. è¯·æ£€æŸ¥registryé…ç½®ä¸­çš„è®¤è¯ä¿¡æ¯æ˜¯å¦æ­£ç¡®\n")
                            log(
                                f"âš ï¸  ç»§ç»­å°è¯•æ¨é€ï¼ˆæ¨é€æ—¶ä¼šä½¿ç”¨auth_configï¼Œä½†å¯èƒ½ä»ç„¶å¤±è´¥ï¼‰\n"
                            )
                        else:
                            log(f"âš ï¸  ç»§ç»­å°è¯•æ¨é€ï¼ˆæ¨é€æ—¶ä¼šä½¿ç”¨auth_configï¼‰\n")
                else:
                    log(f"âš ï¸  registryæœªé…ç½®è®¤è¯ä¿¡æ¯ï¼Œæ¨é€å¯èƒ½å¤±è´¥\n")

                try:
                    log(f"ğŸš€ å¼€å§‹æ¨é€ï¼Œrepository: {push_repository}, tag: {tag}\n")
                    if auth_config:
                        log(
                            f"ğŸ” ä½¿ç”¨è®¤è¯ä¿¡æ¯: username={auth_config.get('username')}, serveraddress={auth_config.get('serveraddress', 'docker.io')}\n"
                        )
                    else:
                        log(f"âš ï¸  æœªä½¿ç”¨è®¤è¯ä¿¡æ¯\n")

                    push_stream = docker_builder.push_image(
                        push_repository, tag, auth_config=auth_config
                    )
                    for chunk in push_stream:
                        status = (
                            chunk.get("status")
                            or chunk.get("progress")
                            or chunk.get("id")
                        )
                        if status:
                            log(f"ğŸ“¡ {status}\n")
                        if "error" in chunk:
                            error_detail = chunk.get("errorDetail", {})
                            error_msg = chunk["error"]
                            log(f"\nâŒ æ¨é€å¤±è´¥: {error_msg}\n")
                            if error_detail:
                                log(f"âŒ é”™è¯¯è¯¦æƒ…: {error_detail}\n")
                            return
                    log(f"\nâœ… æ¨é€å®Œæˆ: {full_tag}\n")
                except Exception as e:
                    error_str = str(e)
                    log(f"\nâŒ æ¨é€å¼‚å¸¸: {error_str}\n")

                    # å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œæä¾›æ›´è¯¦ç»†çš„æç¤º
                    if (
                        "denied" in error_str.lower()
                        or "unauthorized" in error_str.lower()
                        or "401" in error_str
                    ):
                        log(f"ğŸ’¡ æ¨é€è®¤è¯å¤±è´¥ï¼Œå»ºè®®ï¼š\n")
                        log(f"   1. ç¡®è®¤registryé…ç½®ä¸­çš„ç”¨æˆ·åå’Œå¯†ç æ­£ç¡®\n")
                        log(f"   2. å¯¹äºé˜¿é‡Œäº‘registryï¼Œè¯·ä½¿ç”¨ç‹¬ç«‹çš„Registryç™»å½•å¯†ç \n")
                        log(f"   3. å¯ä»¥å°è¯•æ‰‹åŠ¨æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•ï¼š\n")
                        log(
                            f"      docker login --username={push_username} {push_registry_host}\n"
                        )
                        log(f"      docker push {full_tag}\n")
                        log(
                            f"   4. å¦‚æœæ‰‹åŠ¨å‘½ä»¤æˆåŠŸï¼Œè¯´æ˜é…ç½®æœ‰é—®é¢˜ï¼›å¦‚æœä¹Ÿå¤±è´¥ï¼Œè¯´æ˜è®¤è¯ä¿¡æ¯ä¸æ­£ç¡®\n"
                        )

            log("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æ“ä½œå·²å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰\n")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
            self.task_manager.update_task_status(task_id, "completed")

        except Exception as e:
            clean_msg = re.sub(r"[\x00-\x1F\x7F]", " ", str(e)).strip()
            log(f"\nâŒ æ„å»ºå¼‚å¸¸: {clean_msg}\n")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            self.task_manager.update_task_status(task_id, "failed", error=clean_msg)
            import traceback

            traceback.print_exc()
        finally:
            if os.getenv("KEEP_BUILD_CONTEXT", "0") != "1":
                try:
                    shutil.rmtree(build_context, ignore_errors=True)
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å¤±è´¥: {e}")

    def get_logs(self, build_id: str):
        with self.lock:
            return list(self.logs[build_id])

    def start_build_from_source(
        self,
        git_url: str,
        image_name: str,
        tag: str,
        should_push: bool,
        selected_template: str,
        project_type: str = "jar",
        template_params: dict = None,
        push_registry: str = None,
        branch: str = None,
        sub_path: str = None,
        use_project_dockerfile: bool = True,  # æ˜¯å¦ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ä¸­çš„ Dockerfile
        pipeline_id: str = None,  # æµæ°´çº¿IDï¼ˆå¯é€‰ï¼‰
    ):
        """ä» Git æºç å¼€å§‹æ„å»º"""
        try:
            # åˆ›å»ºä»»åŠ¡
            print(f"ğŸ“ æ­£åœ¨åˆ›å»ºæ„å»ºä»»åŠ¡: image={image_name}:{tag}, git_url={git_url}")
            task_id = self.task_manager.create_task(
                task_type="build_from_source",
                image_name=image_name,
                tag=tag,
                git_url=git_url,
                should_push=should_push,
                selected_template=selected_template,
                project_type=project_type,
                template_params=template_params or {},
                push_registry=push_registry,
                branch=branch,
                sub_path=sub_path,
                use_project_dockerfile=use_project_dockerfile,
                pipeline_id=pipeline_id,  # ä¼ é€’æµæ°´çº¿ID
            )
            print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: task_id={task_id}")
        except Exception as e:
            import traceback

            error_trace = traceback.format_exc()
            print(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            print(f"é”™è¯¯å †æ ˆ:\n{error_trace}")
            raise RuntimeError(f"åˆ›å»ºæ„å»ºä»»åŠ¡å¤±è´¥: {str(e)}")

        try:
            thread = threading.Thread(
                target=self._build_from_source_task,
                args=(
                    task_id,
                    git_url,
                    image_name,
                    tag,
                    should_push,
                    selected_template,
                    project_type,
                    template_params or {},
                    push_registry,
                    branch,
                    sub_path,
                    use_project_dockerfile,
                ),
                daemon=True,
            )
            thread.start()
            print(f"âœ… æ„å»ºçº¿ç¨‹å·²å¯åŠ¨: task_id={task_id}")
            with self.lock:
                self.tasks[task_id] = thread
        except Exception as e:
            import traceback

            error_trace = traceback.format_exc()
            print(f"âŒ å¯åŠ¨æ„å»ºçº¿ç¨‹å¤±è´¥: {e}")
            print(f"é”™è¯¯å †æ ˆ:\n{error_trace}")
            # å°è¯•æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            try:
                self.task_manager.update_task_status(
                    task_id, "failed", error=f"å¯åŠ¨æ„å»ºçº¿ç¨‹å¤±è´¥: {str(e)}"
                )
            except:
                pass
            raise RuntimeError(f"å¯åŠ¨æ„å»ºçº¿ç¨‹å¤±è´¥: {str(e)}")

        return task_id

    def _build_from_source_task(
        self,
        task_id: str,
        git_url: str,
        image_name: str,
        tag: str,
        should_push: bool,
        selected_template: str,
        project_type: str = "jar",
        template_params: dict = None,
        push_registry: str = None,
        branch: str = None,
        sub_path: str = None,
        use_project_dockerfile: bool = True,  # æ˜¯å¦ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ä¸­çš„ Dockerfile
    ):
        """ä» Git æºç æ„å»ºä»»åŠ¡"""
        full_tag = f"{image_name}:{tag}"
        # ä½¿ç”¨ task_id ä½œä¸ºæ„å»ºä¸Šä¸‹æ–‡ç›®å½•åçš„ä¸€éƒ¨åˆ†ï¼Œé¿å…å†²çª
        build_context = os.path.join(
            BUILD_DIR, f"{image_name.replace('/', '_')}_{task_id[:8]}"
        )

        def log(msg: str):
            """æ·»åŠ æ—¥å¿—ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
            try:
                if not msg.endswith("\n"):
                    msg = msg + "\n"
                # ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨è®°å½•æ—¥å¿—
                try:
                    self.task_manager.add_log(task_id, msg)
                except Exception as e:
                    # å¦‚æœä»»åŠ¡ç®¡ç†å™¨è®°å½•å¤±è´¥ï¼Œè‡³å°‘æ‰“å°åˆ°æ§åˆ¶å°
                    print(f"âš ï¸ ä»»åŠ¡æ—¥å¿—è®°å½•å¤±è´¥ (task_id={task_id}): {e}")
                    print(f"æ—¥å¿—å†…å®¹: {msg}")
                # ä¿ç•™æ—§çš„æ—¥å¿—ç³»ç»Ÿç”¨äºå…¼å®¹
                try:
                    with self.lock:
                        if task_id not in self.logs:
                            self.logs[task_id] = deque()
                        self.logs[task_id].append(msg)
                except Exception as e:
                    print(f"âš ï¸ æ—§æ—¥å¿—ç³»ç»Ÿè®°å½•å¤±è´¥: {e}")
            except Exception as e:
                # å³ä½¿æ—¥å¿—å‡½æ•°æœ¬èº«å¤±è´¥ï¼Œä¹Ÿè¦æ‰“å°åˆ°æ§åˆ¶å°
                print(f"âš ï¸ æ—¥å¿—å‡½æ•°å¼‚å¸¸: {e}")
                print(f"åŸå§‹æ¶ˆæ¯: {msg}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        try:
            self.task_manager.update_task_status(task_id, "running")
        except Exception as e:
            print(f"âš ï¸ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")

        try:
            log(f"ğŸš€ å¼€å§‹ä» Git æºç æ„å»º: {git_url}\n")

            # æ¸…ç†æ—§çš„æ„å»ºä¸Šä¸‹æ–‡
            if os.path.exists(build_context):
                try:
                    shutil.rmtree(build_context)
                except Exception as e:
                    log(f"âš ï¸ æ¸…ç†æ—§æ„å»ºä¸Šä¸‹æ–‡å¤±è´¥: {e}\n")
            os.makedirs(build_context, exist_ok=True)

            # å…‹éš† Git ä»“åº“
            log(f"ğŸ“¥ æ­£åœ¨å…‹éš† Git ä»“åº“...\n")
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå…‹éš†ï¼ˆGit clone ä¼šåœ¨ç›®æ ‡ç›®å½•ä¸‹åˆ›å»ºä»“åº“ç›®å½•ï¼‰
            temp_clone_dir = os.path.join(build_context, "source_temp")
            os.makedirs(temp_clone_dir, exist_ok=True)

            git_config = get_git_config()
            # Git clone ä¼šåœ¨ç›®æ ‡ç›®å½•ä¸‹åˆ›å»ºä»“åº“ç›®å½•ï¼Œæ‰€ä»¥ç›®æ ‡ç›®å½•åº”è¯¥æ˜¯çˆ¶ç›®å½•
            clone_success = self._clone_git_repo(
                git_url, temp_clone_dir, branch, git_config, log
            )

            if not clone_success:
                raise RuntimeError("Git å…‹éš†å¤±è´¥")

            # Git clone ä¼šåœ¨ç›®æ ‡ç›®å½•ä¸‹åˆ›å»ºä»“åº“ç›®å½•ï¼Œæ‰¾åˆ°å®é™…çš„ä»“åº“ç›®å½•
            # é€šå¸¸ä»“åº“ç›®å½•åæ˜¯ URL çš„æœ€åä¸€éƒ¨åˆ†ï¼ˆå»æ‰ .gitï¼‰
            repo_name = git_url.rstrip("/").split("/")[-1].replace(".git", "")
            actual_clone_dir = os.path.join(temp_clone_dir, repo_name)

            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ temp_clone_dir ä¸‹çš„ç¬¬ä¸€ä¸ªç›®å½•
            if not os.path.exists(actual_clone_dir):
                items = os.listdir(temp_clone_dir)
                if items:
                    actual_clone_dir = os.path.join(temp_clone_dir, items[0])

            if not os.path.exists(actual_clone_dir):
                raise RuntimeError("æ— æ³•æ‰¾åˆ°å…‹éš†çš„ä»“åº“ç›®å½•")

            # å¦‚æœæŒ‡å®šäº†å­ç›®å½•ï¼Œä½¿ç”¨å­ç›®å½•ä½œä¸ºæ„å»ºä¸Šä¸‹æ–‡
            source_dir = actual_clone_dir
            if sub_path:
                source_dir = os.path.join(actual_clone_dir, sub_path)
                if not os.path.exists(source_dir):
                    raise RuntimeError(f"æŒ‡å®šçš„å­ç›®å½•ä¸å­˜åœ¨: {sub_path}")
                log(f"ğŸ“‚ ä½¿ç”¨å­ç›®å½•ä½œä¸ºæ„å»ºä¸Šä¸‹æ–‡: {sub_path}\n")

            # å°†æºç å¤åˆ¶åˆ°æ„å»ºä¸Šä¸‹æ–‡æ ¹ç›®å½•ï¼ˆæ’é™¤ä¸å¿…è¦çš„æ–‡ä»¶ï¼‰
            log(f"ğŸ“‹ å‡†å¤‡æ„å»ºä¸Šä¸‹æ–‡...\n")

            # å®šä¹‰éœ€è¦æ’é™¤çš„æ–‡ä»¶å’Œç›®å½•ï¼ˆç±»ä¼¼ .dockerignoreï¼‰
            exclude_patterns = {
                ".git",
                ".gitignore",
                ".dockerignore",
                "__pycache__",
                "*.pyc",
                ".pytest_cache",
                "node_modules",
                ".venv",
                "venv",
                ".idea",
                ".vscode",
                ".cursor",
                "*.md",
                "*.log",
                ".DS_Store",
                "test_*.py",
                "*_test.py",
            }

            def should_exclude(item_name):
                """åˆ¤æ–­æ–‡ä»¶/ç›®å½•æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
                # ç›´æ¥åŒ¹é…
                if item_name in exclude_patterns:
                    return True
                # é€šé…ç¬¦åŒ¹é…
                import fnmatch

                for pattern in exclude_patterns:
                    if fnmatch.fnmatch(item_name, pattern):
                        return True
                return False

            copied_count = 0
            excluded_count = 0

            for item in os.listdir(source_dir):
                if should_exclude(item):
                    excluded_count += 1
                    log(f"â­ï¸  è·³è¿‡: {item}\n")
                    continue

                src = os.path.join(source_dir, item)
                dst = os.path.join(build_context, item)

                try:
                    if os.path.isdir(src):
                        shutil.copytree(src, dst, dirs_exist_ok=True)
                    else:
                        shutil.copy2(src, dst)
                    copied_count += 1
                except Exception as e:
                    log(f"âš ï¸  å¤åˆ¶å¤±è´¥ {item}: {e}\n")

            log(f"âœ… å·²å¤åˆ¶ {copied_count} ä¸ªæ–‡ä»¶/ç›®å½•ï¼Œè·³è¿‡ {excluded_count} ä¸ª\n")

            # æ£€æŸ¥é¡¹ç›®ä¸­æ˜¯å¦å­˜åœ¨ Dockerfile
            project_dockerfile_path = os.path.join(source_dir, "Dockerfile")
            has_project_dockerfile = os.path.exists(project_dockerfile_path)

            # å†³å®šä½¿ç”¨é¡¹ç›®ä¸­çš„ Dockerfile è¿˜æ˜¯æ¨¡æ¿
            if has_project_dockerfile and use_project_dockerfile:
                log(f"ğŸ“„ æ£€æµ‹åˆ°é¡¹ç›®ä¸­çš„ Dockerfileï¼Œä½¿ç”¨é¡¹ç›®ä¸­çš„ Dockerfile\n")
                # å¤åˆ¶é¡¹ç›®ä¸­çš„ Dockerfile åˆ°æ„å»ºä¸Šä¸‹æ–‡
                dockerfile_path = os.path.join(build_context, "Dockerfile")
                shutil.copy2(project_dockerfile_path, dockerfile_path)
                log(f"âœ… å·²ä½¿ç”¨é¡¹ç›®ä¸­çš„ Dockerfile\n")
            else:
                if has_project_dockerfile and not use_project_dockerfile:
                    log(f"ğŸ“‹ é¡¹ç›®ä¸­æœ‰ Dockerfileï¼Œä½†ç”¨æˆ·é€‰æ‹©ä½¿ç”¨æ¨¡æ¿\n")
                else:
                    log(f"ğŸ“‹ é¡¹ç›®ä¸­æ²¡æœ‰ Dockerfileï¼Œä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ\n")

                # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ Dockerfile
                template_path = get_template_path(selected_template, project_type)
                if not template_path or not os.path.exists(template_path):
                    raise RuntimeError(f"æ¨¡æ¿ä¸å­˜åœ¨: {selected_template}")

                dockerfile_path = os.path.join(build_context, "Dockerfile")
                from backend.template_parser import parse_template

                parse_template(
                    template_path,
                    dockerfile_path,
                    {
                        "PROJECT_TYPE": project_type,
                        "UPLOADED_FILENAME": "app.jar",  # æºç æ„å»ºä¸éœ€è¦è¿™ä¸ª
                        **template_params,
                    },
                )
                log(f"âœ… å·²ç”Ÿæˆ Dockerfile\n")

            # æ„å»ºé•œåƒ
            log(f"ğŸ”¨ å¼€å§‹æ„å»ºé•œåƒ: {full_tag}\n")
            log(f"ğŸ“‚ æ„å»ºä¸Šä¸‹æ–‡: {build_context}\n")
            log(f"ğŸ“„ Dockerfile ç»å¯¹è·¯å¾„: {dockerfile_path}\n")
            # Docker API éœ€è¦ç›¸å¯¹äºæ„å»ºä¸Šä¸‹æ–‡çš„ Dockerfile è·¯å¾„
            dockerfile_relative = os.path.relpath(dockerfile_path, build_context)
            log(f"ğŸ“„ Dockerfile ç›¸å¯¹è·¯å¾„: {dockerfile_relative}\n")
            # åˆ›å»º .dockerignore æ–‡ä»¶ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ„å»ºä¸Šä¸‹æ–‡
            dockerignore_path = os.path.join(build_context, ".dockerignore")
            if not os.path.exists(dockerignore_path):
                log(f"ğŸ“ åˆ›å»º .dockerignore æ–‡ä»¶...\n")
                with open(dockerignore_path, "w") as f:
                    f.write(
                        """# Git ç›¸å…³
.git
.gitignore
.gitattributes

# Python ç¼“å­˜
__pycache__
*.pyc
*.pyo
*.pyd
.Python
.pytest_cache
.venv
venv/

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# IDE
.idea/
.vscode/
.cursor/
*.swp
*.swo
.DS_Store

# æµ‹è¯•å’Œæ–‡æ¡£
test_*.py
*_test.py
*.md
README*
LICENSE

# æ—¥å¿—
*.log
logs/
"""
                    )
                log(f"âœ… .dockerignore å·²åˆ›å»º\n")

            log(f"ğŸ³ å‡†å¤‡è°ƒç”¨ Docker æ„å»ºå™¨...\n")
            try:
                build_stream = docker_builder.build_image(
                    path=build_context, tag=full_tag, dockerfile=dockerfile_relative
                )
                log(f"âœ… Docker æ„å»ºæµå·²å¯åŠ¨\n")
            except Exception as e:
                log(f"âŒ å¯åŠ¨ Docker æ„å»ºå¤±è´¥: {str(e)}\n")
                import traceback

                log(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}\n")
                raise

            log(f"ğŸ” å¼€å§‹å¤„ç† Docker æ„å»ºæµè¾“å‡º...\n")
            chunk_count = 0
            for chunk in build_stream:
                chunk_count += 1
                if isinstance(chunk, dict):
                    # è®°å½•æ‰€æœ‰å­—æ®µï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•ä¿¡æ¯
                    if "stream" in chunk:
                        log(chunk["stream"])  # ç¼–è¯‘æ—¥å¿—åœ¨è¿™é‡Œ
                    if "status" in chunk:
                        log(f"ğŸ“Š {chunk['status']}\n")
                    if "progress" in chunk:
                        log(f"â³ {chunk['progress']}\n")
                    if "error" in chunk:
                        error_msg = chunk["error"]
                        log(f"âŒ æ„å»ºé”™è¯¯: {error_msg}\n")
                        raise RuntimeError(error_msg)
                    if "errorDetail" in chunk:
                        error_detail = chunk["errorDetail"]
                        log(f"ğŸ’¥ é”™è¯¯è¯¦æƒ…: {error_detail}\n")
                    # è®°å½•å…¶ä»–æœªçŸ¥å­—æ®µ
                    unknown_keys = set(chunk.keys()) - {
                        "stream",
                        "status",
                        "progress",
                        "error",
                        "errorDetail",
                        "aux",
                        "id",
                    }
                    if unknown_keys:
                        log(f"ğŸ”§ å…¶ä»–ä¿¡æ¯: {chunk}\n")
                else:
                    log(f"ğŸ“¦ åŸå§‹è¾“å‡º: {str(chunk)}\n")
            log(f"âœ… Docker æ„å»ºæµå¤„ç†å®Œæˆï¼Œå…± {chunk_count} ä¸ªæ•°æ®å—\n")

            log(f"âœ… é•œåƒæ„å»ºå®Œæˆ: {full_tag}\n")

            # å¦‚æœéœ€è¦æ¨é€ï¼Œç›´æ¥ä½¿ç”¨æ„å»ºå¥½çš„é•œåƒåæ¨é€ï¼Œä»æ¿€æ´»çš„registryè·å–è®¤è¯ä¿¡æ¯
            if should_push:
                log(f"ğŸ“¡ å¼€å§‹æ¨é€é•œåƒ...\n")

                # ç›´æ¥ä½¿ç”¨æ„å»ºæ—¶çš„é•œåƒåå’Œæ ‡ç­¾è¿›è¡Œæ¨é€
                # full_tag æ ¼å¼: image_name:tagï¼Œå¯èƒ½åŒ…å«registryè·¯å¾„
                # ä¾‹å¦‚: registry.cn-shanghai.aliyuncs.com/51jbm/jar2docker:dev
                push_repository = image_name  # ç›´æ¥ä½¿ç”¨æ„å»ºæ—¶çš„é•œåƒå

                # æ ¹æ®é•œåƒåæ‰¾åˆ°å¯¹åº”çš„registryé…ç½®
                def find_matching_registry_for_push(image_name):
                    """æ ¹æ®é•œåƒåæ‰¾åˆ°åŒ¹é…çš„registryé…ç½®"""
                    # å¦‚æœé•œåƒååŒ…å«æ–œæ ï¼Œæå–registryéƒ¨åˆ†
                    parts = image_name.split("/")
                    if len(parts) >= 2 and "." in parts[0]:
                        # é•œåƒåæ ¼å¼: registry.com/namespace/image
                        image_registry = parts[0]
                        log(f"ğŸ” ä»é•œåƒåæå–registry: {image_registry}\n")
                        all_registries = get_all_registries()
                        log(f"ğŸ” å…±æœ‰ {len(all_registries)} ä¸ªregistryé…ç½®\n")
                        for reg in all_registries:
                            reg_address = reg.get("registry", "")
                            reg_name = reg.get("name", "Unknown")
                            log(f"ğŸ” æ£€æŸ¥registry: {reg_name}, åœ°å€: {reg_address}\n")
                            if reg_address and (
                                image_registry == reg_address
                                or image_registry.startswith(reg_address)
                                or reg_address.startswith(image_registry)
                            ):
                                log(f"âœ… æ‰¾åˆ°åŒ¹é…çš„registry: {reg_name}\n")
                                return reg
                    return None

                # å°è¯•æ ¹æ®é•œåƒåæ‰¾åˆ°åŒ¹é…çš„registry
                registry_config = find_matching_registry_for_push(image_name)
                if not registry_config:
                    # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ï¼Œä½¿ç”¨æ¿€æ´»çš„registry
                    registry_config = get_active_registry()
                    log(
                        f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„registryé…ç½®ï¼Œä½¿ç”¨æ¿€æ´»ä»“åº“: {registry_config.get('name', 'Unknown')}\n"
                    )
                else:
                    log(
                        f"ğŸ¯ æ‰¾åˆ°åŒ¹é…çš„registryé…ç½®: {registry_config.get('name', 'Unknown')}\n"
                    )

                log(f"ğŸ“¦ æ¨é€é•œåƒ: {full_tag}\n")

                # ä»registryé…ç½®ä¸­è·å–è®¤è¯ä¿¡æ¯
                username = registry_config.get("username")
                password = registry_config.get("password")
                registry_host = registry_config.get("registry", "")

                log(
                    f"ğŸ” Registryé…ç½® - åœ°å€: {registry_host}, ç”¨æˆ·å: {username}, å¯†ç : {'***' if password else '(æœªé…ç½®)'}\n"
                )

                auth_config = None
                if username and password:
                    # æ„å»ºauth_configï¼ŒåŒ…å«registryä¿¡æ¯
                    # docker-pyçš„push APIéœ€è¦serveraddresså­—æ®µæ¥æŒ‡å®šregistry
                    auth_config = {
                        "username": username,
                        "password": password,
                    }
                    # å¯¹äºédocker.ioçš„registryï¼Œå¿…é¡»è®¾ç½®serveraddress
                    # æ³¨æ„ï¼šå¯¹äºé˜¿é‡Œäº‘ç­‰registryï¼Œç›´æ¥ä½¿ç”¨registryåœ°å€ï¼Œä¸éœ€è¦åŠ åè®®
                    if registry_host:
                        if registry_host != "docker.io":
                            # å¯¹äºé˜¿é‡Œäº‘ç­‰registryï¼Œç›´æ¥ä½¿ç”¨registryåœ°å€
                            auth_config["serveraddress"] = registry_host
                        else:
                            # docker.ioä½¿ç”¨æ ‡å‡†åœ°å€
                            auth_config["serveraddress"] = "https://index.docker.io/v1/"
                    else:
                        # å¦‚æœæ²¡æœ‰registry_hostï¼Œé»˜è®¤ä½¿ç”¨docker.io
                        auth_config["serveraddress"] = "https://index.docker.io/v1/"

                    log(f"âœ… å·²é…ç½®è®¤è¯ä¿¡æ¯\n")
                    log(
                        f"ğŸ” Authé…ç½®: username={username}, serveraddress={auth_config.get('serveraddress', 'docker.io')}\n"
                    )

                    # å¯¹äºé˜¿é‡Œäº‘registryï¼Œæ·»åŠ ç‰¹æ®Šæç¤º
                    if registry_host and "aliyuncs.com" in registry_host:
                        log(
                            f"â„¹ï¸  æ£€æµ‹åˆ°é˜¿é‡Œäº‘registryï¼Œè¯·ç¡®ä¿ä½¿ç”¨ç‹¬ç«‹çš„Registryç™»å½•å¯†ç \n"
                        )

                    # æ¨é€å‰å…ˆç™»å½•åˆ°registryï¼ˆé‡è¦ï¼šç¡®ä¿è®¤è¯ç”Ÿæ•ˆï¼‰
                    try:
                        if hasattr(docker_builder, "client") and docker_builder.client:
                            # å¯¹äºé˜¿é‡Œäº‘ç­‰registryï¼Œéœ€è¦ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„registryåœ°å€
                            login_registry = (
                                registry_host
                                if registry_host and registry_host != "docker.io"
                                else None
                            )
                            log(
                                f"ğŸ”‘ æ­£åœ¨ç™»å½•åˆ°registry: {login_registry or 'docker.io'}\n"
                            )
                            log(f"ğŸ”‘ ç”¨æˆ·å: {username}\n")

                            # æ‰§è¡Œç™»å½•
                            login_result = docker_builder.client.login(
                                username=username,
                                password=password,
                                registry=login_registry,
                            )
                            log(f"âœ… ç™»å½•æˆåŠŸ: {login_result}\n")
                        else:
                            log(f"âš ï¸  Dockerå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œè·³è¿‡ç™»å½•\n")
                    except Exception as login_error:
                        error_msg = str(login_error)
                        log(f"âŒ ç™»å½•å¤±è´¥: {error_msg}\n")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                        if (
                            "401" in error_msg
                            or "Unauthorized" in error_msg
                            or "unauthorized" in error_msg
                        ):
                            log(f"âš ï¸  è®¤è¯å¤±è´¥ï¼Œå¯èƒ½çš„åŸå› ï¼š\n")
                            log(f"   1. ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®\n")
                            log(f"   2. å¯¹äºé˜¿é‡Œäº‘registryï¼Œè¯·ç¡®è®¤ï¼š\n")
                            log(
                                f"      - ç”¨æˆ·åï¼šä½¿ç”¨é˜¿é‡Œäº‘è´¦å·æˆ–ç‹¬ç«‹çš„é•œåƒä»“åº“ç”¨æˆ·å\n"
                            )
                            log(f"      - å¯†ç ï¼šä½¿ç”¨é˜¿é‡Œäº‘è´¦å·å¯†ç æˆ–é•œåƒä»“åº“ç‹¬ç«‹å¯†ç \n")
                            log(f"      - å¦‚æœä½¿ç”¨è®¿é—®ä»¤ç‰Œï¼Œè¯·ç¡®è®¤ä»¤ç‰Œæœªè¿‡æœŸ\n")
                            log(f"   3. è¯·æ£€æŸ¥registryé…ç½®ä¸­çš„è®¤è¯ä¿¡æ¯æ˜¯å¦æ­£ç¡®\n")
                            log(
                                f"âš ï¸  ç»§ç»­å°è¯•æ¨é€ï¼ˆæ¨é€æ—¶ä¼šä½¿ç”¨auth_configï¼Œä½†å¯èƒ½ä»ç„¶å¤±è´¥ï¼‰\n"
                            )
                        else:
                            log(f"âš ï¸  ç»§ç»­å°è¯•æ¨é€ï¼ˆæ¨é€æ—¶ä¼šä½¿ç”¨auth_configï¼‰\n")
                else:
                    log(f"âš ï¸  registryæœªé…ç½®è®¤è¯ä¿¡æ¯ï¼Œæ¨é€å¯èƒ½å¤±è´¥\n")

                try:
                    # ç›´æ¥æ¨é€æ„å»ºå¥½çš„é•œåƒ
                    log(f"ğŸš€ å¼€å§‹æ¨é€ï¼Œrepository: {push_repository}, tag: {tag}\n")
                    if auth_config:
                        log(
                            f"ğŸ” ä½¿ç”¨è®¤è¯ä¿¡æ¯: username={auth_config.get('username')}, serveraddress={auth_config.get('serveraddress', 'docker.io')}\n"
                        )
                    else:
                        log(f"âš ï¸  æœªä½¿ç”¨è®¤è¯ä¿¡æ¯\n")

                    push_stream = docker_builder.push_image(
                        push_repository, tag, auth_config=auth_config
                    )
                    for chunk in push_stream:
                        if isinstance(chunk, dict):
                            if "status" in chunk:
                                log(chunk["status"] + "\n")
                            elif "error" in chunk:
                                error_detail = chunk.get("errorDetail", {})
                                error_msg = chunk["error"]
                                log(f"âŒ æ¨é€é”™è¯¯: {error_msg}\n")
                                if error_detail:
                                    log(f"âŒ é”™è¯¯è¯¦æƒ…: {error_detail}\n")
                                raise RuntimeError(chunk["error"])
                        else:
                            log(str(chunk))

                    log(f"âœ… æ¨é€å®Œæˆ: {full_tag}\n")
                except Exception as e:
                    error_str = str(e)
                    log(f"âŒ æ¨é€å¼‚å¸¸: {error_str}\n")

                    # å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œæä¾›æ›´è¯¦ç»†çš„æç¤º
                    if (
                        "denied" in error_str.lower()
                        or "unauthorized" in error_str.lower()
                        or "401" in error_str
                    ):
                        log(f"ğŸ’¡ æ¨é€è®¤è¯å¤±è´¥ï¼Œå»ºè®®ï¼š\n")
                        log(f"   1. ç¡®è®¤registryé…ç½®ä¸­çš„ç”¨æˆ·åå’Œå¯†ç æ­£ç¡®\n")
                        log(f"   2. å¯¹äºé˜¿é‡Œäº‘registryï¼Œè¯·ä½¿ç”¨ç‹¬ç«‹çš„Registryç™»å½•å¯†ç \n")
                        log(f"   3. å¯ä»¥å°è¯•æ‰‹åŠ¨æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•ï¼š\n")
                        log(
                            f"      docker login --username={username} {registry_host}\n"
                        )
                        log(f"      docker push {full_tag}\n")
                        log(
                            f"   4. å¦‚æœæ‰‹åŠ¨å‘½ä»¤æˆåŠŸï¼Œè¯´æ˜é…ç½®æœ‰é—®é¢˜ï¼›å¦‚æœä¹Ÿå¤±è´¥ï¼Œè¯´æ˜è®¤è¯ä¿¡æ¯ä¸æ­£ç¡®\n"
                        )

                    raise

            log(f"âœ… æ‰€æœ‰æ“ä½œå·²å®Œæˆ\n")
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
            self.task_manager.update_task_status(task_id, "completed")

        except Exception as e:
            import traceback

            error_msg = str(e)
            error_trace = traceback.format_exc()

            # å°è¯•è®°å½•é”™è¯¯æ—¥å¿—ï¼Œå³ä½¿logå‡½æ•°å¤±è´¥ä¹Ÿè¦ç¡®ä¿é”™è¯¯è¢«è®°å½•
            try:
                log(f"âŒ æ„å»ºå¤±è´¥: {error_msg}\n")
                log(f"ğŸ“‹ é”™è¯¯å †æ ˆ:\n{error_trace}\n")
            except Exception as log_error:
                # å¦‚æœlogå‡½æ•°å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨ä»»åŠ¡ç®¡ç†å™¨è®°å½•
                print(f"âš ï¸ æ—¥å¿—è®°å½•å¤±è´¥ï¼Œç›´æ¥è®°å½•é”™è¯¯: {log_error}")
                try:
                    self.task_manager.add_log(task_id, f"âŒ æ„å»ºå¤±è´¥: {error_msg}\n")
                    self.task_manager.add_log(task_id, f"ğŸ“‹ é”™è¯¯å †æ ˆ:\n{error_trace}\n")
                except Exception as add_log_error:
                    print(f"âš ï¸ ç›´æ¥è®°å½•æ—¥å¿—ä¹Ÿå¤±è´¥: {add_log_error}")
                    # æœ€åçš„æ‰‹æ®µï¼šæ‰“å°åˆ°æ§åˆ¶å°
                    print(f"âŒ æ„å»ºå¤±è´¥ (task_id={task_id}): {error_msg}")
                    print(f"ğŸ“‹ é”™è¯¯å †æ ˆ:\n{error_trace}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            try:
                self.task_manager.update_task_status(task_id, "failed", error=error_msg)
            except Exception as status_error:
                print(f"âš ï¸ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {status_error}")
                print(f"ä»»åŠ¡ID: {task_id}, é”™è¯¯: {error_msg}")

            traceback.print_exc()
        finally:
            # æ¸…ç†æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼Œä¿ç•™ç”¨äºè°ƒè¯•ï¼‰
            pass
            # if os.path.exists(build_context):
            #     try:
            #         shutil.rmtree(build_context, ignore_errors=True)
            #     except Exception as e:
            #         print(f"âš ï¸ æ¸…ç†å¤±è´¥: {e}")

    def _clone_git_repo(
        self,
        git_url: str,
        clone_dir: str,
        branch: str = None,
        git_config: dict = None,
        log_func=None,
    ):
        """å…‹éš† Git ä»“åº“"""
        try:
            git_config = git_config or {}
            log = log_func or (lambda x: None)

            # å‡†å¤‡ Git å‘½ä»¤
            cmd = ["git", "clone"]

            # å¦‚æœæ˜¯ HTTPS URL ä¸”æœ‰ç”¨æˆ·åå¯†ç ï¼ŒåµŒå…¥åˆ° URL ä¸­
            if (
                git_url.startswith("https://")
                and git_config.get("username")
                and git_config.get("password")
            ):
                # å°†ç”¨æˆ·åå¯†ç åµŒå…¥ URL
                from urllib.parse import urlparse, urlunparse

                parsed = urlparse(git_url)
                auth_url = urlunparse(
                    (
                        parsed.scheme,
                        f"{git_config['username']}:{git_config['password']}@{parsed.netloc}",
                        parsed.path,
                        parsed.params,
                        parsed.query,
                        parsed.fragment,
                    )
                )
                git_url = auth_url
                log("ğŸ” ä½¿ç”¨é…ç½®çš„ç”¨æˆ·åå¯†ç è¿›è¡Œè®¤è¯\n")

            # å¦‚æœæ˜¯ SSH URL ä¸”æœ‰ SSH keyï¼Œé…ç½® SSH
            if git_url.startswith("git@") and git_config.get("ssh_key_path"):
                ssh_key_path = git_config["ssh_key_path"]
                if os.path.exists(ssh_key_path):
                    # è®¾ç½® GIT_SSH_COMMAND ä½¿ç”¨æŒ‡å®šçš„ SSH key
                    os.environ["GIT_SSH_COMMAND"] = (
                        f"ssh -i {ssh_key_path} -o StrictHostKeyChecking=no"
                    )
                    log(f"ğŸ”‘ ä½¿ç”¨ SSH key: {ssh_key_path}\n")

            # å¦‚æœæŒ‡å®šäº†åˆ†æ”¯ï¼Œéœ€è¦åœ¨ URL ä¹‹å‰æ·»åŠ  -b å‚æ•°
            if branch:
                cmd.extend(["-b", branch])
                log(f"ğŸ“Œ æ£€å‡ºåˆ†æ”¯: {branch}\n")

            # Git clone ä¼šåœ¨ç›®æ ‡ç›®å½•ä¸‹åˆ›å»ºä»“åº“ç›®å½•
            # ç¡®å®šä»“åº“åç§°ï¼ˆä» URL æå–ï¼‰
            repo_name = git_url.rstrip("/").split("/")[-1].replace(".git", "")
            target_dir = os.path.join(clone_dir, repo_name)

            cmd.append(git_url)
            cmd.append(target_dir)

            # æ‰§è¡Œå…‹éš†
            # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(target_dir), exist_ok=True)
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œé¿å…è·¯å¾„é—®é¢˜
            abs_target_dir = os.path.abspath(target_dir)
            abs_clone_dir = os.path.abspath(clone_dir)
            # æ›´æ–°å‘½ä»¤ä¸­çš„ç›®æ ‡è·¯å¾„ä¸ºç»å¯¹è·¯å¾„
            cmd[-1] = abs_target_dir

            # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°å®Œæ•´å‘½ä»¤
            log(f"ğŸ”§ å®Œæ•´å‘½ä»¤: {' '.join(cmd)}\n")

            result = subprocess.run(
                cmd,
                cwd=os.path.dirname(abs_clone_dir),
                capture_output=True,
                text=True,
                timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode != 0:
                log(f"âŒ Git å…‹éš†å¤±è´¥: {result.stderr}\n")
                # æ¸…ç†ç¯å¢ƒå˜é‡
                if "GIT_SSH_COMMAND" in os.environ:
                    del os.environ["GIT_SSH_COMMAND"]
                return False

            log(f"âœ… Git ä»“åº“å…‹éš†æˆåŠŸ\n")
            log(f"ğŸ“‚ ä»“åº“å·²å…‹éš†åˆ°: {abs_target_dir}\n")

            # æ¸…ç†ç¯å¢ƒå˜é‡
            if "GIT_SSH_COMMAND" in os.environ:
                del os.environ["GIT_SSH_COMMAND"]

            return True

        except subprocess.TimeoutExpired:
            log("âŒ Git å…‹éš†è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰\n")
            # æ¸…ç†ç¯å¢ƒå˜é‡
            if "GIT_SSH_COMMAND" in os.environ:
                del os.environ["GIT_SSH_COMMAND"]
            return False
        except Exception as e:
            log(f"âŒ Git å…‹éš†å¼‚å¸¸: {str(e)}\n")
            # æ¸…ç†ç¯å¢ƒå˜é‡
            if "GIT_SSH_COMMAND" in os.environ:
                del os.environ["GIT_SSH_COMMAND"]
            return False


# ============ æ„å»ºä»»åŠ¡ç®¡ç†å™¨ ============
class BuildTaskManager:
    """æ„å»ºä»»åŠ¡ç®¡ç†å™¨ - ç®¡ç†é•œåƒæ„å»ºä»»åŠ¡ï¼Œæ”¯æŒå¼‚æ­¥æ„å»ºå’Œæ—¥å¿—å­˜å‚¨"""

    _instance_lock = threading.Lock()
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._init()
        return cls._instance

    def _init(self):
        self.tasks = {}  # task_id -> task_info
        self.lock = threading.Lock()
        self.tasks_dir = os.path.join(BUILD_DIR, "tasks")
        os.makedirs(self.tasks_dir, exist_ok=True)
        self.tasks_file = os.path.join(self.tasks_dir, "tasks.json")

        # ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
        self._load_tasks()

        # å¯åŠ¨è‡ªåŠ¨æ¸…ç†ä»»åŠ¡
        self._start_cleanup_task()

    def _load_tasks(self):
        """ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡åˆ—è¡¨"""
        if not os.path.exists(self.tasks_file):
            return

        try:
            with open(self.tasks_file, "r", encoding="utf-8") as f:
                tasks_data = json.load(f)

            need_save = False
            with self.lock:
                self.tasks = {}
                for task in tasks_data:
                    task_id = task["task_id"]
                    # å¦‚æœä»»åŠ¡çŠ¶æ€æ˜¯ running æˆ– pendingï¼Œæ ‡è®°ä¸ºå¤±è´¥ï¼ˆå› ä¸ºä»»åŠ¡çº¿ç¨‹å·²ä¸¢å¤±ï¼‰
                    if task.get("status") in ("running", "pending"):
                        task["status"] = "failed"
                        task["error"] = "æœåŠ¡é‡å¯ï¼Œä»»åŠ¡ä¸­æ–­"
                        task["completed_at"] = datetime.now().isoformat()
                        need_save = True
                    self.tasks[task_id] = task

            # å¦‚æœæœ‰ä»»åŠ¡è¢«æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¿å­˜æ›´æ–°
            if need_save:
                self._save_tasks()

            print(f"âœ… å·²åŠ è½½ {len(self.tasks)} ä¸ªæ„å»ºä»»åŠ¡")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ„å»ºä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            self.tasks = {}

    def _save_tasks(self):
        """ä¿å­˜ä»»åŠ¡åˆ—è¡¨åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.tasks_file), exist_ok=True)

            with self.lock:
                # åˆ›å»ºå¯åºåˆ—åŒ–çš„ä»»åŠ¡åˆ—è¡¨
                tasks_list = []
                for task in self.tasks.values():
                    try:
                        # å°è¯•åˆ›å»ºä»»åŠ¡å‰¯æœ¬å¹¶éªŒè¯å¯åºåˆ—åŒ–
                        task_copy = task.copy()
                        # ç¡®ä¿ logs æ˜¯åˆ—è¡¨
                        if "logs" not in task_copy:
                            task_copy["logs"] = []
                        # é™åˆ¶ logs é•¿åº¦ä»¥é¿å…åºåˆ—åŒ–é—®é¢˜
                        if (
                            isinstance(task_copy.get("logs"), list)
                            and len(task_copy["logs"]) > 20000
                        ):
                            task_copy["logs"] = task_copy["logs"][-10000:]
                        tasks_list.append(task_copy)
                    except Exception as task_error:
                        print(
                            f"âš ï¸ å¤„ç†ä»»åŠ¡æ—¶å‡ºé”™ (task_id={task.get('task_id', 'unknown')}): {task_error}"
                        )
                        # è·³è¿‡æœ‰é—®é¢˜çš„ä»»åŠ¡ï¼Œç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
                        continue

            # å°è¯•åºåˆ—åŒ–ä»¥éªŒè¯
            try:
                json.dumps(tasks_list)
            except (TypeError, ValueError) as json_error:
                print(f"âš ï¸ ä»»åŠ¡åˆ—è¡¨æ— æ³•åºåˆ—åŒ–: {json_error}")
                # å°è¯•æ¸…ç†æ— æ³•åºåˆ—åŒ–çš„æ•°æ®
                for task in tasks_list:
                    # ç§»é™¤å¯èƒ½æ— æ³•åºåˆ—åŒ–çš„å­—æ®µ
                    if "logs" in task and isinstance(task["logs"], list):
                        # ç¡®ä¿æ‰€æœ‰æ—¥å¿—é¡¹éƒ½æ˜¯å­—ç¬¦ä¸²
                        task["logs"] = [
                            str(log) if not isinstance(log, str) else log
                            for log in task["logs"]
                        ]

            temp_file = f"{self.tasks_file}.tmp"
            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump(tasks_list, f, ensure_ascii=False, indent=2)

            if os.path.exists(self.tasks_file):
                os.replace(temp_file, self.tasks_file)
            else:
                os.rename(temp_file, self.tasks_file)
        except Exception as e:
            import traceback

            error_trace = traceback.format_exc()
            print(f"âš ï¸ ä¿å­˜æ„å»ºä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            print(f"é”™è¯¯å †æ ˆ:\n{error_trace}")
            temp_file = f"{self.tasks_file}.tmp"
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ä»»åŠ¡åˆ›å»ºç»§ç»­

    def _start_cleanup_task(self):
        """å¯åŠ¨è‡ªåŠ¨æ¸…ç†è¿‡æœŸä»»åŠ¡çš„åå°çº¿ç¨‹"""

        def cleanup_loop():
            import time

            while True:
                try:
                    time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                    self.cleanup_expired_tasks()
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†æ„å»ºä»»åŠ¡å‡ºé”™: {e}")

        cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
        cleanup_thread.start()

    def create_task(
        self,
        task_type: str,  # "build" æˆ– "build_from_source"
        image_name: str,
        tag: str = "latest",
        **kwargs,  # å…¶ä»–ä»»åŠ¡å‚æ•°
    ) -> str:
        """åˆ›å»ºæ„å»ºä»»åŠ¡"""
        try:
            task_id = str(uuid.uuid4())
            created_at = datetime.now()

            # ç¡®ä¿ kwargs ä¸­çš„å€¼å¯ä»¥åºåˆ—åŒ–
            serializable_kwargs = {}
            for key, value in kwargs.items():
                try:
                    # å°è¯•åºåˆ—åŒ–ä»¥æ£€æŸ¥æ˜¯å¦å¯åºåˆ—åŒ–
                    json.dumps(value)
                    serializable_kwargs[key] = value
                except (TypeError, ValueError) as e:
                    # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    print(f"âš ï¸ å‚æ•° {key} æ— æ³•åºåˆ—åŒ–ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²: {e}")
                    serializable_kwargs[key] = str(value)

            task_info = {
                "task_id": task_id,
                "task_type": task_type,  # "build" æˆ– "build_from_source"
                "image": image_name,
                "tag": tag,
                "status": "pending",  # pending, running, completed, failed
                "created_at": created_at.isoformat(),
                "completed_at": None,
                "error": None,
                "logs": [],  # ä»»åŠ¡æ—¥å¿—
                **serializable_kwargs,  # å…¶ä»–ä»»åŠ¡å‚æ•°
            }

            with self.lock:
                self.tasks[task_id] = task_info

            # ä¿å­˜ä»»åŠ¡ï¼Œå³ä½¿å¤±è´¥ä¹Ÿä¸å½±å“è¿”å› task_id
            try:
                self._save_tasks()
            except Exception as save_error:
                print(f"âš ï¸ ä¿å­˜ä»»åŠ¡å¤±è´¥ï¼Œä½†ä»»åŠ¡å·²åˆ›å»º (task_id={task_id}): {save_error}")
                # å³ä½¿ä¿å­˜å¤±è´¥ï¼Œä¹Ÿç»§ç»­è¿”å› task_id

            print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ: task_id={task_id}, type={task_type}")
            return task_id
        except Exception as e:
            import traceback

            error_trace = traceback.format_exc()
            print(f"âŒ åˆ›å»ºä»»åŠ¡å¼‚å¸¸: {e}")
            print(f"é”™è¯¯å †æ ˆ:\n{error_trace}")
            raise

    def get_task(self, task_id: str) -> dict:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        with self.lock:
            return self.tasks.get(task_id, {}).copy()

    def list_tasks(self, status: str = None, task_type: str = None) -> list:
        """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
        with self.lock:
            tasks = list(self.tasks.values())
            if status:
                tasks = [t for t in tasks if t["status"] == status]
            if task_type:
                tasks = [t for t in tasks if t.get("task_type") == task_type]
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            tasks.sort(key=lambda x: x["created_at"], reverse=True)
            return [t.copy() for t in tasks]

    def update_task_status(self, task_id: str, status: str, error: str = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        with self.lock:
            if task_id in self.tasks:
                self.tasks[task_id]["status"] = status
                if error:
                    self.tasks[task_id]["error"] = error
                if status in ("completed", "failed"):
                    self.tasks[task_id]["completed_at"] = datetime.now().isoformat()

                    # ä»»åŠ¡å®Œæˆæˆ–å¤±è´¥æ—¶ï¼Œè§£ç»‘æµæ°´çº¿
                    try:
                        from backend.pipeline_manager import PipelineManager

                        pipeline_manager = PipelineManager()
                        pipeline_id = pipeline_manager.find_pipeline_by_task(task_id)
                        if pipeline_id:
                            pipeline_manager.unbind_task(pipeline_id)
                            print(
                                f"âœ… ä»»åŠ¡ {task_id[:8]} å·²å®Œæˆï¼Œè§£ç»‘æµæ°´çº¿ {pipeline_id[:8]}"
                            )
                    except Exception as e:
                        print(f"âš ï¸ è§£ç»‘æµæ°´çº¿å¤±è´¥: {e}")
        self._save_tasks()

    def add_log(self, task_id: str, log_message: str):
        """æ·»åŠ ä»»åŠ¡æ—¥å¿—ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
        try:
            with self.lock:
                if task_id in self.tasks:
                    if "logs" not in self.tasks[task_id]:
                        self.tasks[task_id]["logs"] = []
                    # é™åˆ¶æ—¥å¿—æ•°é‡ï¼Œé¿å…å†…å­˜è¿‡å¤§
                    if len(self.tasks[task_id]["logs"]) > 10000:
                        self.tasks[task_id]["logs"] = self.tasks[task_id]["logs"][
                            -5000:
                        ]
                    self.tasks[task_id]["logs"].append(log_message)
                else:
                    # ä»»åŠ¡ä¸å­˜åœ¨ï¼Œè‡³å°‘æ‰“å°åˆ°æ§åˆ¶å°
                    print(f"âš ï¸ ä»»åŠ¡ä¸å­˜åœ¨ (task_id={task_id})ï¼Œæ— æ³•è®°å½•æ—¥å¿—")
                    print(f"æ—¥å¿—å†…å®¹: {log_message}")

            # æ¯100æ¡æ—¥å¿—ä¿å­˜ä¸€æ¬¡ï¼Œæˆ–è€…å¦‚æœæ˜¯å…³é”®æ—¥å¿—ï¼ˆé”™è¯¯ã€å®Œæˆï¼‰åˆ™ç«‹å³ä¿å­˜
            should_save = False
            with self.lock:
                if task_id in self.tasks:
                    log_count = len(self.tasks[task_id].get("logs", []))
                    # å…³é”®æ—¥å¿—å…³é”®è¯
                    is_critical = any(
                        keyword in log_message
                        for keyword in ["âŒ", "âœ…", "ERROR", "FAIL", "å®Œæˆ", "å¤±è´¥"]
                    )
                    # æ¯100æ¡æˆ–å…³é”®æ—¥å¿—ä¿å­˜
                    should_save = (log_count % 100 == 0) or is_critical

            if should_save:
                try:
                    self._save_tasks()
                except Exception as save_error:
                    print(f"âš ï¸ ä¿å­˜ä»»åŠ¡æ—¥å¿—å¤±è´¥: {save_error}")
        except Exception as e:
            # å³ä½¿è®°å½•æ—¥å¿—å¤±è´¥ï¼Œä¹Ÿè¦æ‰“å°åˆ°æ§åˆ¶å°
            print(f"âš ï¸ æ·»åŠ ä»»åŠ¡æ—¥å¿—å¼‚å¸¸ (task_id={task_id}): {e}")
            print(f"æ—¥å¿—å†…å®¹: {log_message}")

    def get_logs(self, task_id: str) -> str:
        """è·å–ä»»åŠ¡æ—¥å¿—"""
        with self.lock:
            task = self.tasks.get(task_id)
            if not task:
                return ""
            logs = task.get("logs", [])
            return "".join(logs)

    def delete_task(self, task_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡"""
        with self.lock:
            if task_id not in self.tasks:
                return False
            del self.tasks[task_id]
        self._save_tasks()
        return True

    def cleanup_expired_tasks(self):
        """æ¸…ç†è¿‡æœŸä»»åŠ¡ï¼ˆè¶…è¿‡1å¤©ï¼‰"""
        cutoff_time = datetime.now() - timedelta(days=1)
        cutoff_iso = cutoff_time.isoformat()

        with self.lock:
            expired_tasks = [
                task_id
                for task_id, task in self.tasks.items()
                if task.get("created_at", "") < cutoff_iso
            ]

            for task_id in expired_tasks:
                del self.tasks[task_id]

        if expired_tasks:
            self._save_tasks()
            print(f"ğŸ§¹ å·²æ¸…ç† {len(expired_tasks)} ä¸ªè¿‡æœŸæ„å»ºä»»åŠ¡")


# ============ å¯¼å‡ºä»»åŠ¡ç®¡ç†å™¨ ============
class ExportTaskManager:
    """å¯¼å‡ºä»»åŠ¡ç®¡ç†å™¨ - ç®¡ç†é•œåƒå¯¼å‡ºä»»åŠ¡ï¼Œæ”¯æŒå¼‚æ­¥å¯¼å‡ºå’Œæ–‡ä»¶å­˜å‚¨"""

    _instance_lock = threading.Lock()
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._init()
        return cls._instance

    def _init(self):
        self.tasks = {}  # task_id -> task_info
        self.lock = threading.Lock()
        self.tasks_dir = os.path.join(EXPORT_DIR, "tasks")
        os.makedirs(self.tasks_dir, exist_ok=True)
        self.tasks_file = os.path.join(self.tasks_dir, "tasks.json")

        # ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
        self._load_tasks()

        # å¯åŠ¨è‡ªåŠ¨æ¸…ç†ä»»åŠ¡
        self._start_cleanup_task()

    def _load_tasks(self):
        """ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡åˆ—è¡¨"""
        if not os.path.exists(self.tasks_file):
            return

        try:
            with open(self.tasks_file, "r", encoding="utf-8") as f:
                tasks_data = json.load(f)

            need_save = False
            with self.lock:
                self.tasks = {}
                for task in tasks_data:
                    task_id = task["task_id"]
                    # å¦‚æœä»»åŠ¡çŠ¶æ€æ˜¯ running æˆ– pendingï¼Œæ ‡è®°ä¸ºå¤±è´¥ï¼ˆå› ä¸ºä»»åŠ¡çº¿ç¨‹å·²ä¸¢å¤±ï¼‰
                    if task.get("status") in ("running", "pending"):
                        task["status"] = "failed"
                        task["error"] = "æœåŠ¡é‡å¯ï¼Œä»»åŠ¡ä¸­æ–­"
                        task["completed_at"] = datetime.now().isoformat()
                        need_save = True
                    # å¦‚æœä»»åŠ¡å·²å®Œæˆä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ ‡è®°ä¸ºå¤±è´¥
                    elif task.get("status") == "completed":
                        file_path = task.get("file_path")
                        if file_path and not os.path.exists(file_path):
                            task["status"] = "failed"
                            task["error"] = "ä»»åŠ¡æ–‡ä»¶å·²ä¸¢å¤±"
                            task["completed_at"] = datetime.now().isoformat()
                            need_save = True
                    self.tasks[task_id] = task

            # å¦‚æœæœ‰ä»»åŠ¡è¢«æ ‡è®°ä¸ºå¤±è´¥ï¼Œä¿å­˜æ›´æ–°ï¼ˆåœ¨é”å¤–è°ƒç”¨ï¼Œé¿å…æ­»é”ï¼‰
            if need_save:
                self._save_tasks()

            print(f"âœ… å·²åŠ è½½ {len(self.tasks)} ä¸ªå¯¼å‡ºä»»åŠ¡")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            self.tasks = {}

    def _save_tasks(self):
        """ä¿å­˜ä»»åŠ¡åˆ—è¡¨åˆ°æ–‡ä»¶ï¼ˆä¸æŒæœ‰é”ï¼Œé¿å…æ­»é”ï¼‰"""
        try:
            # å…ˆå¤åˆ¶æ•°æ®ï¼Œé¿å…é•¿æ—¶é—´æŒæœ‰é”
            with self.lock:
                tasks_list = [task.copy() for task in self.tasks.values()]

            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶ååŸå­æ€§æ›¿æ¢
            temp_file = f"{self.tasks_file}.tmp"
            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump(tasks_list, f, ensure_ascii=False, indent=2)

            # åŸå­æ€§æ›¿æ¢
            if os.path.exists(self.tasks_file):
                os.replace(temp_file, self.tasks_file)
            else:
                os.rename(temp_file, self.tasks_file)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_file = f"{self.tasks_file}.tmp"
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass

    def _start_cleanup_task(self):
        """å¯åŠ¨è‡ªåŠ¨æ¸…ç†è¿‡æœŸä»»åŠ¡çš„åå°çº¿ç¨‹"""

        def cleanup_loop():
            import time

            while True:
                try:
                    time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                    self.cleanup_expired_tasks()
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†ä»»åŠ¡å‡ºé”™: {e}")

        cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
        cleanup_thread.start()

    def create_task(
        self,
        image: str,
        tag: str = "latest",
        compress: str = "none",
        registry: str = None,
        use_local: bool = False,
    ) -> str:
        """åˆ›å»ºå¯¼å‡ºä»»åŠ¡"""
        task_id = str(uuid.uuid4())
        created_at = datetime.now()

        task_info = {
            "task_id": task_id,
            "task_type": "export",  # æ·»åŠ ä»»åŠ¡ç±»å‹æ ‡è¯†
            "image": image,
            "tag": tag,
            "compress": compress,
            "registry": registry,
            "use_local": use_local,  # æ˜¯å¦ä½¿ç”¨æœ¬åœ°ä»“åº“ï¼ˆä¸æ‰§è¡Œ pullï¼‰
            "status": "pending",  # pending, running, completed, failed
            "created_at": created_at.isoformat(),
            "completed_at": None,
            "file_path": None,
            "file_size": None,
            "error": None,
        }

        with self.lock:
            self.tasks[task_id] = task_info

        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_tasks()

        # å¯åŠ¨å¯¼å‡ºä»»åŠ¡
        thread = threading.Thread(
            target=self._export_task,
            args=(task_id,),
            daemon=True,
        )
        thread.start()

        return task_id

    def _export_task(self, task_id: str):
        """æ‰§è¡Œå¯¼å‡ºä»»åŠ¡"""
        with self.lock:
            if task_id not in self.tasks:
                return
            task_info = self.tasks[task_id]
            task_info["status"] = "running"

        # ä¿å­˜çŠ¶æ€æ›´æ–°
        self._save_tasks()

        try:
            image = task_info["image"]
            tag = task_info["tag"]
            compress = task_info["compress"]
            registry = task_info["registry"]

            if not DOCKER_AVAILABLE:
                raise RuntimeError("Docker æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯¼å‡ºé•œåƒ")

            # è·å–è®¤è¯ä¿¡æ¯
            from backend.config import (
                get_all_registries,
                get_active_registry,
                get_registry_by_name,
            )

            registry_config = None
            if registry:
                registry_config = get_registry_by_name(registry)
                if not registry_config:
                    raise RuntimeError(f"æŒ‡å®šçš„ä»“åº“ '{registry}' ä¸å­˜åœ¨")

            if not registry_config:
                # å°è¯•æ™ºèƒ½åŒ¹é…ä»“åº“
                def find_matching_registry_for_export(image_name):
                    parts = image_name.split("/")
                    if len(parts) >= 2 and "." in parts[0]:
                        image_registry = parts[0]
                        all_registries = get_all_registries()
                        for reg in all_registries:
                            reg_address = reg.get("registry", "")
                            if reg_address and (
                                image_registry == reg_address
                                or image_registry.startswith(reg_address)
                                or reg_address.startswith(image_registry)
                            ):
                                return reg
                    return None

                registry_config = find_matching_registry_for_export(image)
                if not registry_config:
                    registry_config = get_active_registry()

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æœ¬åœ°ä»“åº“
            use_local = task_info.get("use_local", False)

            if not use_local:
                # éœ€è¦ä»è¿œç¨‹ä»“åº“æ‹‰å–é•œåƒ
                username = registry_config.get("username")
                password = registry_config.get("password")
                auth_config = None
                if username and password:
                    auth_config = {"username": username, "password": password}

                # æ‹‰å–é•œåƒ
                pull_stream = docker_builder.pull_image(image, tag, auth_config)
                for chunk in pull_stream:
                    if "error" in chunk:
                        raise RuntimeError(chunk["error"])

            full_tag = f"{image}:{tag}"
            # æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨ï¼ˆæœ¬åœ°æˆ–å·²æ‹‰å–ï¼‰
            docker_builder.get_image(full_tag)

            # åˆ›å»ºä»»åŠ¡æ–‡ä»¶ç›®å½•
            task_dir = os.path.join(self.tasks_dir, task_id)
            os.makedirs(task_dir, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            safe_base = get_safe_filename(image.replace("/", "_") or "image")
            tar_filename = f"{safe_base}-{tag}-{timestamp}.tar"
            tar_path = os.path.join(task_dir, tar_filename)

            # å¯¼å‡ºé•œåƒ
            image_stream = docker_builder.export_image(full_tag)
            with open(tar_path, "wb") as f:
                for chunk in image_stream:
                    f.write(chunk)

            final_path = tar_path
            file_size = os.path.getsize(tar_path)

            # å¦‚æœéœ€è¦å‹ç¼©
            if compress.lower() in ("gzip", "gz", "tgz", "1", "true", "yes"):
                final_path = f"{tar_path}.gz"
                with open(tar_path, "rb") as src, gzip.open(final_path, "wb") as dst:
                    shutil.copyfileobj(src, dst)
                os.remove(tar_path)
                file_size = os.path.getsize(final_path)

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            with self.lock:
                if task_id in self.tasks:
                    self.tasks[task_id]["status"] = "completed"
                    self.tasks[task_id]["completed_at"] = datetime.now().isoformat()
                    self.tasks[task_id]["file_path"] = final_path
                    self.tasks[task_id]["file_size"] = file_size

            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_tasks()

        except Exception as e:
            import traceback

            error_msg = str(e)
            traceback.print_exc()
            with self.lock:
                if task_id in self.tasks:
                    self.tasks[task_id]["status"] = "failed"
                    self.tasks[task_id]["completed_at"] = datetime.now().isoformat()
                    self.tasks[task_id]["error"] = error_msg

            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_tasks()

    def get_task(self, task_id: str) -> dict:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        with self.lock:
            return self.tasks.get(task_id, {}).copy()

    def list_tasks(self, status: str = None) -> list:
        """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
        with self.lock:
            tasks = list(self.tasks.values())
            if status:
                tasks = [t for t in tasks if t["status"] == status]
            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
            tasks.sort(key=lambda x: x["created_at"], reverse=True)
            return [t.copy() for t in tasks]

    def get_task_file_path(self, task_id: str) -> str:
        """è·å–ä»»åŠ¡æ–‡ä»¶è·¯å¾„"""
        with self.lock:
            task = self.tasks.get(task_id)
            if not task:
                raise ValueError(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            if task["status"] != "completed":
                raise ValueError(f"ä»»åŠ¡ {task_id} å°šæœªå®Œæˆ")
            file_path = task.get("file_path")
            if not file_path or not os.path.exists(file_path):
                raise ValueError(f"ä»»åŠ¡æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return file_path

    def delete_task(self, task_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡åŠå…¶æ–‡ä»¶"""
        with self.lock:
            if task_id not in self.tasks:
                return False
            task = self.tasks[task_id]
            file_path = task.get("file_path")
            task_dir = os.path.join(self.tasks_dir, task_id)

            # åˆ é™¤æ–‡ä»¶
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")

            # åˆ é™¤ä»»åŠ¡ç›®å½•
            if os.path.exists(task_dir):
                try:
                    shutil.rmtree(task_dir, ignore_errors=True)
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥: {e}")

            # åˆ é™¤ä»»åŠ¡è®°å½•
            del self.tasks[task_id]

        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_tasks()
        return True

    def cleanup_expired_tasks(self, days: int = 1):
        """æ¸…ç†è¿‡æœŸä»»åŠ¡ï¼ˆé»˜è®¤ä¿ç•™1å¤©ï¼‰"""
        from datetime import timedelta

        cutoff_time = datetime.now() - timedelta(days=days)

        expired_task_ids = []
        with self.lock:
            for task_id, task in self.tasks.items():
                created_at = datetime.fromisoformat(task["created_at"])
                if created_at < cutoff_time:
                    expired_task_ids.append(task_id)

        for task_id in expired_task_ids:
            try:
                self.delete_task(task_id)
                print(f"ğŸ—‘ï¸ å·²æ¸…ç†è¿‡æœŸä»»åŠ¡: {task_id}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä»»åŠ¡å¤±è´¥ {task_id}: {e}")


# ============ æ“ä½œæ—¥å¿—ç®¡ç†å™¨ ============
class OperationLogger:
    """æ“ä½œæ—¥å¿—ç®¡ç†å™¨ - è®°å½•ç”¨æˆ·æ“ä½œ"""

    _instance_lock = threading.Lock()
    _instance = None
    _logs_file = None

    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._init()
        return cls._instance

    def _init(self):
        os.makedirs(LOGS_DIR, exist_ok=True)
        self._logs_file = os.path.join(LOGS_DIR, "operations.jsonl")
        self.lock = threading.Lock()

    @classmethod
    def log(cls, username: str, operation: str, details: dict = None):
        """è®°å½•æ“ä½œæ—¥å¿—"""
        instance = cls()
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "username": username,
            "operation": operation,
            "details": details or {},
        }

        try:
            with instance.lock:
                with open(instance._logs_file, "a", encoding="utf-8") as f:
                    f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"âš ï¸ è®°å½•æ“ä½œæ—¥å¿—å¤±è´¥: {e}")

    def get_logs(self, limit: int = 100, username: str = None, operation: str = None):
        """è·å–æ“ä½œæ—¥å¿—"""
        if not os.path.exists(self._logs_file):
            return []

        logs = []
        try:
            with open(self._logs_file, "r", encoding="utf-8") as f:
                for line in f:
                    if not line.strip():
                        continue
                    try:
                        log_entry = json.loads(line)
                        # è¿‡æ»¤
                        if username and log_entry.get("username") != username:
                            continue
                        if operation and log_entry.get("operation") != operation:
                            continue
                        logs.append(log_entry)
                    except json.JSONDecodeError:
                        continue

            # æŒ‰æ—¶é—´å€’åºæ’åˆ—
            logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
            return logs[:limit]
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ“ä½œæ—¥å¿—å¤±è´¥: {e}")
            return []

    def clear_logs(self, days: int = None):
        """æ¸…ç†æ“ä½œæ—¥å¿—

        Args:
            days: ä¿ç•™æœ€è¿‘ N å¤©çš„æ—¥å¿—ï¼Œå¦‚æœä¸º None åˆ™æ¸…ç©ºæ‰€æœ‰æ—¥å¿—

        Returns:
            æ¸…ç†çš„æ—¥å¿—æ¡æ•°
        """
        if not os.path.exists(self._logs_file):
            return 0

        try:
            with self.lock:
                if days is None:
                    # æ¸…ç©ºæ‰€æœ‰æ—¥å¿—
                    with open(self._logs_file, "w", encoding="utf-8") as f:
                        f.write("")
                    return 0
                else:
                    # ä¿ç•™æœ€è¿‘ N å¤©çš„æ—¥å¿—
                    cutoff_time = datetime.now() - timedelta(days=days)
                    cutoff_iso = cutoff_time.isoformat()

                    kept_logs = []
                    removed_count = 0

                    with open(self._logs_file, "r", encoding="utf-8") as f:
                        for line in f:
                            if not line.strip():
                                continue
                            try:
                                log_entry = json.loads(line)
                                timestamp = log_entry.get("timestamp", "")
                                if timestamp >= cutoff_iso:
                                    kept_logs.append(line)
                                else:
                                    removed_count += 1
                            except json.JSONDecodeError:
                                continue

                    # å†™å›ä¿ç•™çš„æ—¥å¿—
                    with open(self._logs_file, "w", encoding="utf-8") as f:
                        for line in kept_logs:
                            f.write(line)

                    return removed_count
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ“ä½œæ—¥å¿—å¤±è´¥: {e}")
            raise
