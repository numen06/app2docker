# backend/database.py
"""æ•°æ®åº“é…ç½®å’Œä¼šè¯ç®¡ç†"""
import os
from sqlalchemy import create_engine, event
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import StaticPool
import threading
import sqlite3

# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_DIR = "data"
DB_FILE = os.path.join(DB_DIR, "app2docker.db")
DB_URL = f"sqlite:///{DB_FILE}"

# SQLiteè¿æ¥å‚æ•°ï¼Œä¼˜åŒ–å¹¶å‘æ€§èƒ½
connect_args = {
    "check_same_thread": False,
    "timeout": 30.0,  # ç­‰å¾…é”çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
}

# åˆ›å»ºæ•°æ®åº“å¼•æ“
# ä½¿ç”¨ StaticPool å’Œ check_same_thread=False ä»¥æ”¯æŒå¤šçº¿ç¨‹
engine = create_engine(
    DB_URL,
    connect_args=connect_args,
    poolclass=StaticPool,
    echo=False,  # è®¾ç½®ä¸º True å¯ä»¥æŸ¥çœ‹ SQL è¯­å¥
    pool_pre_ping=True,  # è¿æ¥å‰pingï¼Œæ£€æµ‹è¿æ¥æ˜¯å¦æœ‰æ•ˆ
)


# å¯ç”¨WALæ¨¡å¼ä»¥æé«˜å¹¶å‘æ€§èƒ½
@event.listens_for(engine, "connect")
def set_sqlite_pragma(dbapi_conn, connection_record):
    """è®¾ç½®SQLiteçš„PRAGMAé€‰é¡¹ä»¥æé«˜å¹¶å‘æ€§èƒ½"""
    cursor = dbapi_conn.cursor()
    try:
        # WALæ¨¡å¼ï¼šWrite-Ahead Loggingï¼Œæé«˜å¹¶å‘è¯»å†™æ€§èƒ½
        cursor.execute("PRAGMA journal_mode=WAL")
        # è®¾ç½®åŒæ­¥æ¨¡å¼ä¸ºNORMALï¼ˆåœ¨WALæ¨¡å¼ä¸‹æ›´å®‰å…¨ï¼‰
        cursor.execute("PRAGMA synchronous=NORMAL")
        # è®¾ç½®ç¼“å­˜å¤§å°ï¼ˆ64MBï¼‰
        cursor.execute("PRAGMA cache_size=-65536")
        # è®¾ç½®ä¸´æ—¶å­˜å‚¨ä¸ºå†…å­˜
        cursor.execute("PRAGMA temp_store=MEMORY")
        # è®¾ç½®å¿™ç­‰å¾…è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
        cursor.execute("PRAGMA busy_timeout=30000")
    except Exception as e:
        print(f"âš ï¸ è®¾ç½®SQLite PRAGMAå¤±è´¥: {e}")
    finally:
        cursor.close()


# åˆ›å»ºä¼šè¯å·¥å‚
SessionLocal = scoped_session(
    sessionmaker(autocommit=False, autoflush=False, bind=engine)
)

# çº¿ç¨‹æœ¬åœ°å­˜å‚¨
_local = threading.local()


def get_db():
    """è·å–æ•°æ®åº“ä¼šè¯ï¼ˆç”¨äºä¾èµ–æ³¨å…¥ï¼‰"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def get_db_session():
    """è·å–æ•°æ®åº“ä¼šè¯ï¼ˆç”¨äºç›´æ¥è°ƒç”¨ï¼‰"""
    return SessionLocal()


def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼ˆåˆ›å»ºæ‰€æœ‰è¡¨ï¼‰"""
    from backend.models import Base

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(DB_DIR, exist_ok=True)

    # åœ¨åˆ›å»ºè¡¨ä¹‹å‰ï¼Œå…ˆè®¾ç½®WALæ¨¡å¼ï¼ˆå¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼‰
    if os.path.exists(DB_FILE):
        try:
            conn = sqlite3.connect(DB_FILE, timeout=30.0)
            cursor = conn.cursor()
            cursor.execute("PRAGMA journal_mode=WAL")
            cursor.execute("PRAGMA synchronous=NORMAL")
            cursor.execute("PRAGMA cache_size=-65536")
            cursor.execute("PRAGMA temp_store=MEMORY")
            cursor.execute("PRAGMA busy_timeout=30000")
            conn.close()
        except Exception as e:
            print(f"âš ï¸ è®¾ç½®æ•°æ®åº“PRAGMAå¤±è´¥: {e}")

    # åˆ›å»ºæ‰€æœ‰è¡¨
    Base.metadata.create_all(bind=engine)

    # è¿ç§»ï¼šæ·»åŠ webhook_allowed_brancheså­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    migrate_add_webhook_allowed_branches()
    
    # è¿ç§»ï¼šæ·»åŠ Portainerç›¸å…³å­—æ®µåˆ°agent_hostsè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    migrate_add_portainer_fields()
    
    # è¿ç§»ï¼šä¿®æ”¹tokenå­—æ®µå…è®¸NULLï¼ˆå¦‚æœè¡¨å·²å­˜åœ¨ä¸”tokenå­—æ®µä¸å…è®¸NULLï¼‰
    migrate_token_nullable()
    
    # è¿ç§»ï¼šä¿®å¤JSONå­—æ®µçš„æ— æ•ˆæ•°æ®
    migrate_fix_json_fields()
    
    # è¿ç§»ï¼šæ·»åŠ started_atå­—æ®µåˆ°tasksè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    migrate_add_started_at_field()

    print(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {DB_FILE}")


def migrate_add_webhook_allowed_branches():
    """è¿ç§»ï¼šä¸ºpipelinesè¡¨æ·»åŠ webhook_allowed_brancheså­—æ®µ"""
    if not os.path.exists(DB_FILE):
        return

    try:
        conn = sqlite3.connect(DB_FILE, timeout=30.0)
        cursor = conn.cursor()

        # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
        cursor.execute("PRAGMA table_info(pipelines)")
        columns = [row[1] for row in cursor.fetchall()]

        if "webhook_allowed_branches" not in columns:
            print("ğŸ”„ æ·»åŠ  webhook_allowed_branches å­—æ®µåˆ° pipelines è¡¨...")
            # SQLiteä¸æ”¯æŒç›´æ¥æ·»åŠ JSONåˆ—ï¼Œéœ€è¦å…ˆæ·»åŠ TEXTåˆ—
            cursor.execute(
                "ALTER TABLE pipelines ADD COLUMN webhook_allowed_branches TEXT DEFAULT '[]'"
            )
            conn.commit()
            print("âœ… webhook_allowed_branches å­—æ®µæ·»åŠ æˆåŠŸ")
        else:
            print("âœ… webhook_allowed_branches å­—æ®µå·²å­˜åœ¨")

        conn.close()
    except sqlite3.OperationalError as e:
        if "duplicate column name" in str(e).lower():
            print("âœ… webhook_allowed_branches å­—æ®µå·²å­˜åœ¨")
        else:
            print(f"âš ï¸ è¿ç§»webhook_allowed_brancheså­—æ®µå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ è¿ç§»webhook_allowed_brancheså­—æ®µå¤±è´¥: {e}")


def migrate_add_portainer_fields():
    """è¿ç§»ï¼šä¸ºagent_hostsè¡¨æ·»åŠ Portainerç›¸å…³å­—æ®µ"""
    if not os.path.exists(DB_FILE):
        return

    try:
        conn = sqlite3.connect(DB_FILE, timeout=30.0)
        cursor = conn.cursor()

        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='agent_hosts'")
        if not cursor.fetchone():
            conn.close()
            return

        # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
        cursor.execute("PRAGMA table_info(agent_hosts)")
        columns = [row[1] for row in cursor.fetchall()]

        # æ·»åŠ  host_type å­—æ®µ
        if "host_type" not in columns:
            print("ğŸ”„ æ·»åŠ  host_type å­—æ®µåˆ° agent_hosts è¡¨...")
            cursor.execute(
                "ALTER TABLE agent_hosts ADD COLUMN host_type VARCHAR(20) DEFAULT 'agent'"
            )
            conn.commit()
            print("âœ… host_type å­—æ®µæ·»åŠ æˆåŠŸ")
        
        # æ·»åŠ  portainer_url å­—æ®µ
        if "portainer_url" not in columns:
            print("ğŸ”„ æ·»åŠ  portainer_url å­—æ®µåˆ° agent_hosts è¡¨...")
            cursor.execute(
                "ALTER TABLE agent_hosts ADD COLUMN portainer_url VARCHAR(512)"
            )
            conn.commit()
            print("âœ… portainer_url å­—æ®µæ·»åŠ æˆåŠŸ")
        
        # æ·»åŠ  portainer_api_key å­—æ®µ
        if "portainer_api_key" not in columns:
            print("ğŸ”„ æ·»åŠ  portainer_api_key å­—æ®µåˆ° agent_hosts è¡¨...")
            cursor.execute(
                "ALTER TABLE agent_hosts ADD COLUMN portainer_api_key TEXT"
            )
            conn.commit()
            print("âœ… portainer_api_key å­—æ®µæ·»åŠ æˆåŠŸ")
        
        # æ·»åŠ  portainer_endpoint_id å­—æ®µ
        if "portainer_endpoint_id" not in columns:
            print("ğŸ”„ æ·»åŠ  portainer_endpoint_id å­—æ®µåˆ° agent_hosts è¡¨...")
            cursor.execute(
                "ALTER TABLE agent_hosts ADD COLUMN portainer_endpoint_id INTEGER"
            )
            conn.commit()
            print("âœ… portainer_endpoint_id å­—æ®µæ·»åŠ æˆåŠŸ")

        conn.close()
    except sqlite3.OperationalError as e:
        if "duplicate column name" in str(e).lower():
            print("âœ… Portainer ç›¸å…³å­—æ®µå·²å­˜åœ¨")
        else:
            print(f"âš ï¸ è¿ç§»Portainerå­—æ®µå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ è¿ç§»Portainerå­—æ®µå¤±è´¥: {e}")


def migrate_token_nullable():
    """è¿ç§»ï¼šä¿®æ”¹agent_hostsè¡¨çš„tokenå­—æ®µå…è®¸NULL"""
    if not os.path.exists(DB_FILE):
        return

    try:
        conn = sqlite3.connect(DB_FILE, timeout=30.0)
        cursor = conn.cursor()

        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='agent_hosts'")
        if not cursor.fetchone():
            conn.close()
            return

        # æ£€æŸ¥tokenå­—æ®µçš„å®šä¹‰
        cursor.execute("PRAGMA table_info(agent_hosts)")
        columns = cursor.fetchall()
        
        token_column = None
        for col in columns:
            if col[1] == 'token':  # col[1] æ˜¯åˆ—å
                token_column = col
                break
        
        if token_column:
            # col[3] æ˜¯ notnull æ ‡å¿—ï¼ˆ1è¡¨ç¤ºNOT NULLï¼Œ0è¡¨ç¤ºå…è®¸NULLï¼‰
            if token_column[3] == 1:
                print("ğŸ”„ ä¿®æ”¹ token å­—æ®µå…è®¸ NULL...")
                # SQLiteä¸æ”¯æŒç›´æ¥ä¿®æ”¹åˆ—çº¦æŸï¼Œéœ€è¦é‡å»ºè¡¨
                # 1. åˆ›å»ºæ–°è¡¨
                cursor.execute("""
                    CREATE TABLE agent_hosts_new (
                        host_id VARCHAR(36) PRIMARY KEY,
                        name VARCHAR(255) NOT NULL UNIQUE,
                        host_type VARCHAR(20) DEFAULT 'agent',
                        token VARCHAR(64) UNIQUE,
                        portainer_url VARCHAR(512),
                        portainer_api_key TEXT,
                        portainer_endpoint_id INTEGER,
                        status VARCHAR(20) DEFAULT 'offline',
                        last_heartbeat DATETIME,
                        host_info TEXT DEFAULT '{}',
                        docker_info TEXT DEFAULT '{}',
                        description TEXT DEFAULT '',
                        created_at DATETIME,
                        updated_at DATETIME
                    )
                """)
                
                # 2. å¤åˆ¶æ•°æ®ï¼ˆæ˜ç¡®æŒ‡å®šåˆ—é¡ºåºï¼Œç¡®ä¿ JSON å­—æ®µæ­£ç¡®ï¼‰
                cursor.execute("""
                    INSERT INTO agent_hosts_new (
                        host_id, name, host_type, token, portainer_url, portainer_api_key, 
                        portainer_endpoint_id, status, last_heartbeat, host_info, docker_info, 
                        description, created_at, updated_at
                    )
                    SELECT 
                        host_id, name, 
                        COALESCE(host_type, 'agent') as host_type,
                        token, portainer_url, portainer_api_key, portainer_endpoint_id,
                        COALESCE(status, 'offline') as status,
                        last_heartbeat,
                        CASE 
                            WHEN typeof(host_info) = 'text' AND host_info IS NOT NULL 
                            THEN host_info 
                            ELSE '{}' 
                        END as host_info,
                        CASE 
                            WHEN typeof(docker_info) = 'text' AND docker_info IS NOT NULL 
                            THEN docker_info 
                            ELSE '{}' 
                        END as docker_info,
                        COALESCE(description, '') as description,
                        created_at, updated_at
                    FROM agent_hosts
                """)
                
                # 3. åˆ é™¤æ—§è¡¨
                cursor.execute("DROP TABLE agent_hosts")
                
                # 4. é‡å‘½åæ–°è¡¨
                cursor.execute("ALTER TABLE agent_hosts_new RENAME TO agent_hosts")
                
                # 5. é‡æ–°åˆ›å»ºç´¢å¼•
                cursor.execute("CREATE UNIQUE INDEX idx_agent_host_token ON agent_hosts(token)")
                cursor.execute("CREATE INDEX idx_agent_host_status ON agent_hosts(status)")
                cursor.execute("CREATE INDEX idx_agent_host_name ON agent_hosts(name)")
                cursor.execute("CREATE INDEX idx_agent_host_type ON agent_hosts(host_type)")
                
                conn.commit()
                print("âœ… token å­—æ®µå·²ä¿®æ”¹ä¸ºå…è®¸ NULL")
            else:
                print("âœ… token å­—æ®µå·²å…è®¸ NULL")
        else:
            print("âš ï¸ æœªæ‰¾åˆ° token å­—æ®µ")

        conn.close()
    except sqlite3.OperationalError as e:
        if "no such table" in str(e).lower():
            print("âœ… agent_hosts è¡¨ä¸å­˜åœ¨ï¼Œæ— éœ€è¿ç§»")
        else:
            print(f"âš ï¸ è¿ç§»tokenå­—æ®µå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ è¿ç§»tokenå­—æ®µå¤±è´¥: {e}")


def migrate_add_started_at_field():
    """è¿ç§»ï¼šä¸ºtasksè¡¨æ·»åŠ started_atå­—æ®µ"""
    if not os.path.exists(DB_FILE):
        return

    try:
        conn = sqlite3.connect(DB_FILE, timeout=30.0)
        cursor = conn.cursor()

        # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
        cursor.execute("PRAGMA table_info(tasks)")
        columns = [row[1] for row in cursor.fetchall()]

        if "started_at" not in columns:
            print("ğŸ”„ æ·»åŠ  started_at å­—æ®µåˆ° tasks è¡¨...")
            cursor.execute(
                "ALTER TABLE tasks ADD COLUMN started_at DATETIME"
            )
            conn.commit()
            print("âœ… started_at å­—æ®µæ·»åŠ æˆåŠŸ")
        else:
            print("âœ… started_at å­—æ®µå·²å­˜åœ¨")

        conn.close()
    except sqlite3.OperationalError as e:
        if "duplicate column name" in str(e).lower():
            print("âœ… started_at å­—æ®µå·²å­˜åœ¨")
        else:
            print(f"âš ï¸ è¿ç§»started_atå­—æ®µå¤±è´¥: {e}")
    except Exception as e:
        print(f"âš ï¸ è¿ç§»started_atå­—æ®µå¤±è´¥: {e}")


def migrate_fix_json_fields():
    """è¿ç§»ï¼šä¿®å¤agent_hostsè¡¨ä¸­host_infoå’Œdocker_infoå­—æ®µçš„æ— æ•ˆJSONæ•°æ®"""
    if not os.path.exists(DB_FILE):
        return

    try:
        conn = sqlite3.connect(DB_FILE, timeout=30.0)
        cursor = conn.cursor()

        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='agent_hosts'")
        if not cursor.fetchone():
            conn.close()
            return

        # è·å–æ‰€æœ‰è®°å½•
        cursor.execute("SELECT host_id, host_info, docker_info FROM agent_hosts")
        rows = cursor.fetchall()
        
        fixed_count = 0
        for row in rows:
            host_id, host_info, docker_info = row
            
            # ä¿®å¤ host_info
            host_info_fixed = None
            try:
                if host_info:
                    # å°è¯•è§£æ JSON
                    import json
                    json.loads(host_info)
                    host_info_fixed = host_info
                else:
                    host_info_fixed = '{}'
            except (json.JSONDecodeError, TypeError):
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œé‡ç½®ä¸ºç©ºå¯¹è±¡
                host_info_fixed = '{}'
                fixed_count += 1
            
            # ä¿®å¤ docker_info
            docker_info_fixed = None
            try:
                if docker_info:
                    # å°è¯•è§£æ JSON
                    import json
                    json.loads(docker_info)
                    docker_info_fixed = docker_info
                else:
                    docker_info_fixed = '{}'
            except (json.JSONDecodeError, TypeError):
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œé‡ç½®ä¸ºç©ºå¯¹è±¡
                docker_info_fixed = '{}'
                fixed_count += 1
            
            # å¦‚æœæ•°æ®éœ€è¦ä¿®å¤ï¼Œæ›´æ–°è®°å½•
            if host_info_fixed != host_info or docker_info_fixed != docker_info:
                cursor.execute("""
                    UPDATE agent_hosts 
                    SET host_info = ?, docker_info = ?
                    WHERE host_id = ?
                """, (host_info_fixed, docker_info_fixed, host_id))
        
        if fixed_count > 0:
            conn.commit()
            print(f"âœ… ä¿®å¤äº† {fixed_count} æ¡è®°å½•çš„ JSON å­—æ®µ")
        else:
            print("âœ… JSON å­—æ®µæ•°æ®æ­£å¸¸")

        conn.close()
    except Exception as e:
        print(f"âš ï¸ ä¿®å¤JSONå­—æ®µå¤±è´¥: {e}")


def close_db():
    """å…³é—­æ•°æ®åº“è¿æ¥"""
    SessionLocal.remove()
